[
  {
    "objectID": "about.html",
    "href": "about.html",
    "title": "Blog",
    "section": "",
    "text": "Welcome to the blog! Here you‚Äôll find posts on technical writing, machine learning, and more.\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nInteractive Grey Wolf Optimization\n\n\n\n\n\n\n\n\nDec 12, 2025\n\n\nRitwik Raha\n\n\n\n\n\n\n\n\n\n\n\n\nNotes on Technical Writing\n\n\n\n\n\n\n\n\nDec 29, 2024\n\n\nRitwik Raha\n\n\n\n\n\n\n\n\n\n\n\n\nMixture of Experts for Dummies\n\n\n\n\n\n\n\n\nDec 7, 2023\n\n\nRitwik Raha\n\n\n\n\n\n\n\n\n\n\n\n\nUnderstanding AugMix\n\n\n\n\n\n\n\n\nJul 24, 2023\n\n\nRitwik Raha\n\n\n\n\n\n\n\n\n\n\n\n\nWhat is Computational Photography\n\n\n\n\n\n\n\n\nJan 18, 2022\n\n\nRitwik Raha\n\n\n\n\n\n\n\n\n\n\n\n\nThe Math of Photoshop Blend Modes\n\n\n\n\n\n\n\n\nNov 9, 2021\n\n\nRitwik Raha\n\n\n\n\n\n\n\n\n\n\n\n\nWhy model decay using the exponential function?\n\n\n\n\n\n\n\n\nSep 14, 2021\n\n\nRitwik Raha\n\n\n\n\n\n\n\n\n\n\n\n\nA Brief Introduction to Do-Calculus\n\n\n\n\n\n\n\n\nAug 10, 2021\n\n\nRitwik Raha\n\n\n\n\n\n\n\n\n\n\n\n\nStudying Causality: The good, the bad, and the ugly.\n\n\n\n\n\n\n\n\nApr 28, 2021\n\n\nRitwik Raha\n\n\n\n\n\n\n\n\n\n\n\n\nWhat do we mean when we talk about Causal Inference?\n\n\n\n\n\n\n\n\nApr 12, 2021\n\n\nRitwik Raha\n\n\n\n\n\nNo matching items"
  },
  {
    "objectID": "posts/2021-11-09-the-math-of-photoshop-blend-modes.html",
    "href": "posts/2021-11-09-the-math-of-photoshop-blend-modes.html",
    "title": "The Math of Photoshop Blend Modes",
    "section": "",
    "text": "Photoshop is a wonderful tool for working with images. It is a delight to work with as a designer and it is an instrument to marvel at as a Computer Vision engineer.\nBut the most used feature of Photoshop (atleast for me) is the blend-modes. From time immemorial I have wondered how these work and how do they create beautiful combination of images.\n\n\n\nblend-modes\n\n\nIn this blog we will learn the following:\n\nHow do photoshop blend modes work?\nThe math behind some blend modes\nRecreating blend modes using python\n\n\nUnder the hood of blend modes\nTo begin with, let us first try to understand what is a blend mode. The idea is to blend two different images to produce a third image. Now there are different rules for blending and each of them results in a different output image. The easiest way to think of this is as a function.\n\\[o = f(x,y)\\]\nwhere \\[x\\] and \\[y\\] are the input images, \\[o\\] is the output image, and the function is the process of blending.\n\n\n\nblend-modes-operation\n\n\nNote: x and y represent color(RGB) values of the image\nAs we devise different functions we will create different blend modes. Sounds simple right?\nLet us go through some blend modes and understand how they work:\n\n\nSome simple blend modes\nIn this blog we will look at four simple blend modes:\n\nNormal\nMultiply\nScreen\nOverlay\n\nWe will also cover the mathematical intution for these modes and how to easily code them up using python. We load and display the images using OpenCV and matplotlib. For the blending operations we use numpy.\nYou can download the entire source code of this blogpost from here.\nNormal\nThe first one is always the most simple one. When two images are placed over each other this mode will choose to show only the top image. Mathematically we can express this like:\n\\[f(x,y) = y\\]\nThis is also called alpha-composting. It is relatively easy to code.\ndef normal(imgA,imgB):\n  # make a copy of the second image\n  imgBlended = np.copy(imgB)\n  # convert the image back into uint8 \n  imgOut=(imgBlended*255).astype(np.uint8)\n  # return the blended image\n  return imgOut\nWe take two images and then create a copy of the second image. This image is passed back as output.\nMultiply\nNext we have the second most used blending mode. Before we go into the theory, imagine this:\nYou have the scanned signature of your parent and you want to place it on your leave application. You open up your image editing software and place the two images as you want them. But it does not look real. Something seems off.\nThis is where multiply comes in. This takes the value of each pixel of the first image and multiplies it with each corresponding pixel of the second image. The output image is darker across all pixels than either of the previous values.\nMathematically we can express this as:\n\\[f(x,y) = xy\\]\nThis is also quite easy to code up.\ndef multiply(imgA,imgB):\n  # create a container for the blended image\n  imgBlended = np.zeros_like(imgA)\n  # apply the blending formula to the images\n  imgBlended = imgA*imgB\n  # convert the image back into uint8\n  imgOut=(imgBlended*255).astype(np.uint8)\n  # return th blended image\n  return imgOut\nIn the above method we first create a container to hold the blended image. Then we store the product of the two images and store it in imgBlended. It is then converted back into uint8 format and passed back.\nScreen\nNow the multiply blend mode makes the composite image look darker. What if we want the composite image to be brighter instead?\nYes we can simply invert what we did in the multiply blend mode to achieve that. First we invert the two images and multiply them. Then we invert the result. The formula would look something like this:\n\\[f(x,y) = (1-(1-x)(1-y))\\]\nLet us see how to express this in code:\ndef screen(imgA,imgB):\n  # create a container for the blended image\n  imgBlended = np.zeros_like(imgA)\n  # apply the blending formula to the images\n  imgBlended = (1-(1-imgA)*(1-imgB))\n  # convert the image back into uint8\n  imgOut=(imgBlended*255).astype(np.uint8)\n  # return the blended image\n  return imgOut\nIn the above method we first create a container for the output image. Then we apply the operation to the two images and store the output in imgBlended. It is then converted back into uint8 format and passed back.\nOverlay\nLife is not seen in only light and dark and neither are images. While darkening and brightening an image are quite useful, it is also necessary to be adaptive. Overlay brings in the best of both blending modes.\nWhen the pixels of the first image is dark the pixels of the composite image is darker, when the pixels of the first image is light the pixels of the composite image is lighter. Usually the threshold is set at 0.5. The formula can be expressed as:\n\\[f(x,y) = \\begin{cases}\n    2xy, & \\text{if $x&lt;0.5$}.\\\\\n    1-2(1-a)(1-b), & \\text{otherwise}.\n  \\end{cases}\\]\nLet us see how we can code this up:\ndef overlay(imgA,imgB):\n  # create a mask of the image A everywhere\n  # the pixels are greater than 0.5\n  mask = imgA &gt;= 0.5\n  # create a container for the blended image\n  imgBlended = np.zeros_like(imgA)\n  # apply the blending formula to the mask\n  imgBlended[~mask] = (2*imgA*imgB)[~mask]\n  imgBlended[mask] = (1-2*(1-imgA)*(1-imgB))[mask]\n  # convert the image back into uint8\n  imgOut=(imgBlended*255).astype(np.uint8)\n  # return the blended image\n  return imgOut\nIn the above method we create a mask for the threshold(wherever the first image has values over 0.5). Next we create a container for the blended image and store the belnd operation values in it. For everywhere other than the mask values we apply the multiply like operation and for everywhere else we apply the screen like operation.\n\n\nSource Code\nYou can download the entire source code of this blogpost from here.\n\n\nConclusion\nThere we have it! Our first batch of photoshop like blend modes are now ready. And the best thing?\nWe built them from scracth!\nLet‚Äôs see what our result looks like:\n\n\n\nblend-modes-result\n\n\nNow, needless to say this barely scratches the surface. Real image processing applications like Photoshop have a lot going on under the hood. The calculations are much more streamlined and sophisticated. They also have an array of other blend modes.\n\n\n\nblend-modes-result\n\n\nThis repository aims to faithfully replicate these calculations to some degree. The actual literature of the blnd modes used by Adobe is also provided here.\nHowever what we learned here today gives us a good starting point to understand and minimally recreate blend-modes.\n\n\nReferences\n\nImage Blend Modes - Wikipedia\nAdobe Blend Modes Gudielines\nBlending Modes Explained - Photoshop training channel\nThe Math behind Blend Modes - Imagineer\nBlend Modes in Python\nPillow Blend Modes"
  },
  {
    "objectID": "posts/2021-04-28-studying-causality-the-good-the-bad-and-the-ugly.html",
    "href": "posts/2021-04-28-studying-causality-the-good-the-bad-and-the-ugly.html",
    "title": "Studying Causality: The good, the bad, and the ugly.",
    "section": "",
    "text": "Welcome back to Part 2 of The Causal Blog. The previous one was all about introducing Causality in the briefest way possible. You can find it right here.\nPicking up where we left off let us revise what we learned in Part 1.\n\nIgnoring hidden causes in data can mean death for your model\nCounterfactual thinking is a must\nRandomization, Natural Experiments and Conditioning are the tools of the trade\n\nRight. Now that we have got that sorted, let us start with those three vague terms. Randomization, natural experiments, and conditioning, what are they? How do we use them with our data and why do we need to care?\nWell let us start scratching the list one item at a time.\n\nRandomization\nSo what do we mean when we talk about Randomization in the context of Causality. Well at the very core of it causal knowledge, prefers intervention, in fact, it demands it. What do I mean by that?\nIn very simple terms if you say A causes B, you must be able to show to some degree that in the absence of A and all other parameters staying constant B will not occur.\nNow that is a fairly straightforward statement but the implications go deeper. Say suppose you want to prove that ads by ads on Netflix will cause users to delete accounts. That‚Äôs a decent assumption, and you start trying to prove it. You remove the cause, (Netflix ads) and try to study the behavior of the user, but here‚Äôs the catch, you are not exactly studying user behavior. The other parameters are not kept constant. You are not looking at a parallel world where a doppelganger of the user is not shown an ad when they open Netflix.\nThis is exactly what randomization tries to solve. It basically tells us that in the context of our experiment (ads on Netflix) if we create a set of users and then randomly assign a user to a group (one group gets shown ads and the other group doesn‚Äôt) then we are essentially keeping the ‚Äúother parameters‚Äù constant.\n\n\n\nexample1\n\n\nTwo ways we can achieve randomization are:\n\nA/B testing\nMulti-armed bandits\n\n\nA/B Test\nThis is exactly what we were talking about a second back. Create two groups of subjects (A & B group) and treat them differently (ads vs no ads) and see which one of the groups meets the target (cancellation of subscription). So in summary the steps to be followed are :\n\nCreate two groups of subjects\nExpose each of the groups to two different experiments\nFind out which meets the target\n\nThe Causal Estimate (CE) for this methodology is the difference in outcome due to option 1 and option 2.\n\\[\nCE = Y_{option1} - Y_{option2}\n\\]\n\nCheck out how Netflix actually uses A/B testing in this video.\n\n\n\nMulti-armed bandits\nThe second and a little less famous of the randomization strategy is multi-armed bandits. This methodology derives its name from the arms of slot machines. Historically, the infamous problem goes as such:\nGiven multiple slot machines, a gambler has to decide which arms to pull and how many times in order to maximize profit. Needless to say, countless have been slain by this problem, purely to quench their mathematical curiosity. üòâ\nThis method relies on a very interesting strategy known as Explore & Exploit. Explore as in explore all possible options in the given context of the problem and Exploit as in figure out the best option and keep repeating it to maximize target outcome.\nOne example of this would if you had to figure out which Baskin Robbin‚Äôs ice cream would give you the maximum satisfaction (target outcome). The steps listed down below are some of the ways to carry out Exploration & Exploitation while maximizing satisfaction.\n\n\n\nexample2\n\n\n\nExplore only. This basically means everyday you go to Baskin Robbins and select a new flavor and try it out and see if it gives you maximum satisfaction.\nExploit only. On the first 10 days, you go to Baskin Robbins and try out 10 different flavors. From the 11th day, you keep buying that one flavor that gave you maximum satisfaction from those 10 previously tested ones.\n\nEpsilon - greedy.\n\nStrike a balance between explore an exploit\nSet an initial epsilon (indicator)\nBased on the value of epsilon (randomly picked) we will either explore or exploit.\nIf we exploit, then we pick the best ice cream from already gathered data, if we explore then we randomly pick an ice cream from the counter.\n\n\\[Y_b\\] = target outcome is the best possible, \\[Y_c\\] = current target outcome and \\[CE\\] = Causal Estimate\n\n\n\\[\nCE = Y_b - Y_c\n\\]\n\nUse multi-armed bandits only and only if you have a good number of options to test.\n\n\nThe verdict?\n\n\nUse Randomization even it means staying up a couple of nights and designing an experiment in which you have to create a parallel universe. In all seriousness, the two methods shown above actually gives us a good structure through which we can shape randomized experiments that give us a sense of causal direction.\n\n\n\n\nNatural Experiments\nYep, randomization is hard and if there is absolutely no way for you to intervene, then that ship has sailed. So let us have a look at what the next best option is. Natural Experiments is a way to test causality by shaping naturally occurring phenomenon as an experiment. Its kind of like cheating but in a scientific way. ü§£\nThe two most prevalent ways to do this are as follows:\n\nRegression Discontinuity\nInstrumental Variables\n\n\nRegression Discontinuity\nLet us imagine that we are the top-secret evil society that controls the funding for academic labs. We want to check if granting more funds will cause an increase in lab performance, but there is a catch funding is also dependent on the number of papers published i.e.¬†number of papers published will have to be above a certain threshold (theta) for the lab to qualify for funding.\n\n\n\nexample2\n\n\n\\[\ny = B_0 +B_1x +B_2(x&gt;x_t)+e\n\\]\nUse the linear regression model to estimate the outcome however and this may be counter-intuitive if there is a discontinuous jump at the point where \\(x =x_t\\) or when your threshold is reached. The measure of this discontinuity is your Causal Estimate. If there is a small jump it means funding probably does not play a big role in lab performance and we can continue to be greedy evil super-villains. If the jump is huge enough, then we have got problems and might have to release some of our super-villain money as research grants.\n\n\nInstrumental Variable\nBefore we dive deep into this particular let us revise some of the concepts we glided past previously.\nOutcome Variable. This is a notation (almost always Y) used to denote the final outcome of our causal experiments.\nTreatment Variable. This is another useful notation (almost always t) used to denote the treatment in our causal experiments. In the context of the Netflix ads problem t = showing ads on Netflix or t = not showing ads on Netflix.\nInstrumental Variable = This is used to denote the variable which affects our outcome through our treatment variable. This variable does not have the scope to affect the outcome directly but influences the treatment variable and thereby indirectly affects the outcome.\nConfused? Let‚Äôs take a look at an example:\nImagine we have now joined a publishing company as a data scientist. A strange rumor is abuzz in the marketing department. It is believed that more Twitter mentions will always cause more book sales. As data scientists only we can debunk or solidify this rumor.\n Graph for scenario 1\n Graph for scenario 2\nConsider the following:\nLet us try to model the two causal graphs shown above using simple regression equations. A list of notations is given below:\n\n\\[bs_{orig}\\] = Original figure for book sales.\n\\[tm\\] = Original number of twitter mentions.\n\\[\\hat{tm}\\] = Generated number of twitter mentions from regression equations.\n\\[bs\\] = Generated number of book sales from regression equations.\n\\[CE\\] = Causal Estimate from the experiment\nThe terms \\[B_0\\], \\[B_1\\], \\[B_2\\], \\[B_3\\], \\[B_4\\] and \\[e\\] are regression co-effecients and error terms.\n\nNow let us see how a regression equation for the first figure will look like.\n\\[\nbs_{orig} = B_0 + B_1(tm) + e\n\\]\nNow as author tweeting is going to be our instrumental variable let us frame a different regression equation.\n\\[\ntm = B_1 + B_2(at)+e\n\\]\n\\[B_o\\], \\[B_1\\] and \\[e\\] is used through a method of least squares to generate \\(\\hat{tm}\\). This is different from \\(tm\\) as this has been generated specifically using the variable of author tweeting excerpts. This \\(\\hat{tm}\\) will now be used in anothe regression equation to generate the new figure for book sales.\n\\[\nbs = B_3 + B_4(\\hat{tm}) + e\n\\]\n\\[\nCE = bs - bs_{orig}\n\\]\n\nThe verdict?\n\n\nIf you have a scenario like the ones we presented and there are naturally occurring experiments like academic grants for labs above a certain threshold and author tweeting excerpts from their books, do go for methodologies that leverage these occurrences. This will always give us a better edge and in the end present a better rounded picture of cause and effect.\n\n\n\n\nObservational Data\nNow comes the hard part. You can‚Äôt intervene and create randomized experiments. You can‚Äôt find occurences in your data that qualify as natural experiments. All you are left with cold hard observational data from 2 years back. This is the most explored and most complex part of causal analysis.\nTLDR;\nYou are doomed.\nLargely speaking to estimate causality from observational data only there are 3 major steps.\n\nAssume a graphical model\nMake stratifications (different groups)\nCompare the treatment across stratifications\n\nHow do we do this? Again we have 2 strategies that are quite failproof and widely used.\n\nA lot of these methods are more theoretical, which means you‚Äôll probably have to spend more time with a notebook figuring out all the variables before jumping into code/math.\n\n\nBackdoor Criterion\nBlock all the backdoor paths i.e.¬†block all the non-causal associations and study the final outcome based on the treatment. So what is a backdoor criterion again?\nA set of variables W satisfies the backdoor criteria if the following are true:\n\nW blocks all the backdoor paths from treatment (t) to outcome (Y)\nW does not contain any descendants of treatment (t).\n\nWait, so what is a backdoor?\nWell there are a lot of mathematical jargon available to define it but the general thumb-rule is\n\nArrows pointing away from treatment (t) are front doors.\nArrows pointing towards treatment (t) are backdoors.\n\n Graph with only frontdoor\n Graph with both front door and backdoor\nNow if we simply hold W or any other variable like W which is on a backdoor path as constant we will effectively close that backdoor path. Allowing us to measure the effect of treatment (t) on the outcome (Y).\n\nTest 1:\n\n\nLet‚Äôs try a little test of knowledge shall we? Given the graphical model down below, explain how you‚Äôll use Backdoor Criterion to estimate causal effect. You can write your explanation in the comments.\n\n\n\n\ngraph3bd\n\n\n\n\nPropensity Score Matching\nThis is another strategy that proves really useful when finding out causal effects from observational data. The steps to perform Propensity Score Matching are a bit complicated, but let‚Äôs break them down into chunks. We will also use an example to better understand the strategy.\nLet us suppose we are a multi-national bank and we are trying to find out if winning a lottery causes people to invest more into stocks.\n\n\n\ngraph4fd\n\n\n\nFirst, we find the propensity score i.e.¬†the probability/likelihood that the individual receives a certain treatment. In the above example, this will be the probability that a certain individual wins the lottery.\nMatch the individuals that have matching propensity scores. If we have a matching probability score of two individuals then we match them together. Nearest neighbor matching and greedy optimal matching are some of the techniques.\nVerify the quality of matches. So if two individuals having a similar chance of winning a lottery is matched, we verify the matching using statistical methods. These methods are t-test, standardized bias and can also be done using graphical representations.\nOutcome Analysis. Check how many of those matches(groups) won the lottery. In this step we try to find the mean outcome across matches and study the trend. This gives us an estimate of the causal effect over a number of groups.\n\n\nThe verdict?\n\n\nThis is the toughest of the lot. Remember causal connections are heavily dependent on counterfactual thinking but shaping existing data and conditioning on particular parameters and variables to prove a hypotheses can be a tiresome and sometimes thankless job.\n\n\n\n\nFinal Thoughts\nI realize this was quite bigger than I promised. My hope was to provide a sense of the various methodologies and examples in one place so that it can be used as a reference in times of need. From the next blog onwards we will focus on each of these segments and try to look at some examples and notebooks (python codes) to understand causality. If you have any constructive feedback do let me know in the comments.\n\n\nReferences\n\nCausal Inference in Online Systems by Amit Sharma\nAn awesome playlist for Causal Learning"
  },
  {
    "objectID": "posts/2022-01-18-what-is-computational-photography.html",
    "href": "posts/2022-01-18-what-is-computational-photography.html",
    "title": "What is Computational Photography",
    "section": "",
    "text": "Computational photography refers to digital image capture and processing techniques that use digital computation instead of optical processes. - Wikipedia\n\n\n\n\nSource: Apple Computational Photography\n\n\nThat is a neat definition, but what does it mean?\n‚ÄúIf we take a picture on instagram and apply a filter on it, is that computational photography?‚Äù\n‚ÄúWhat if we digitally enhance our photographs after we take them?‚Äù\n‚ÄúWhat about instagram filters?‚Äù\n\nTL;DR\nIn its simplest form computational photography means anything that leverages the power of computer vision and image processing to artificially enhance photographs. This could be anything from a snapchat filter to an extremely sophisticated piece of code stitching together the first ever image of a black hole.\nBut before we fully understand what computational photography means let us go through a brief lesson on photography.\n\n\nA primer on Photography\nIn simple terms we have a device which creates images by recording light reflected from real world objects on a sensor.\nThis means a camera essentially records light. Every little detail in a camera is to optimize that goal perfectly.\nSo if we zoom out a little and see the big picture, there are three main components to photography.\n\nHow much light is entering the device? (The aperture)\nHow long we are allowing the light to enter? (The shutter speed)\nHow sensitive is the sensor to the light? (ISO)\n\nIf you are already familiar with these terms, and have some experience in creating images with various combinations of these parameters feel free to skip to the next section.\nAnd now, if you are still here, let us get started with the basic components of a camera.\n\nAperture\nFirst we talk about Aperture. Now before we go all technical I want you to imagine something for me.\nFor a second, imagine that you are leaving a movie theatre. As you walk out, you are suddenly blinded by a flash of white light. You squeeze your eyes shut. It takes a couple of seconds for your eyes to readjust themselves to the brightness, and you slowly open them up again.\nSounds familiar?\nThis is exactly what aperture means.\nIt is the measure of how much the lens is opened. It is usually measured in f-stops and expressed in numbers such as 1.4,1.8,2,2.8,5.6,8,11,16.\nSomething to remember here is that the lower the number is the bigger the opening of the lens. The higher the f-stop is the smaller the opening of the lens.\n\nBut what effect does this have on the image?\n\nWell if you have a bigger opening you have more light or more information coming through. So a smaller aperture or larger f-stop would lead to darker pictures and vice versa.\n\n\n\nSource: A Beginners Guide to Photography\n\n\n\nThat‚Äôs great, what else can we do using aperture?\n\n\nThe Aperture also controls Depth-Of-Field.\n\n\nWhat is Depth-Of-Field?\n\nDepth-of-Field is simply the distance between the nearest and the farthest object in the camera‚Äôs viewing field which are in acceptable focus.\nBy acceptable focus we mean that we can make out the details of the object.\n\nBut how is this connected to aperture?\n\nWell, the bigger the aperture the more light is allowed into the sensor creating a shallow depth of field for the background and vice versa.\n\n\n\nSource: What Is F-Stop & How to Use It for Photography\n\n\n\n\nShutter Speed\nShutter speed is exactly what the name says. It is the speed with which the camera goes khiichiiik. This is usually measured in a fraction of a second for example, 1/10 th of a second. We can see numbers like 1/10,1/20,1/50,1/100,‚Ä¶,1/640.\nSo before I bring in the diagrams and the math, let me ask you a simple question-\n\nWhat happens if we take a low shutter speed like 1/10?\n\nThe camera sensor stays open for a longer period of time right? This means we are allowing more light to enter. Our image will be brighter.\nSimilarly if we have a faster shutter speed, we will not give much time for the senor to be exposed to light. This means our image would be eventually darker.\n\n\n\nSource: Shutter Speed: Everything You Need To Know\n\n\n\nThis is great? Anything else?\n\nAbsolutely! We want to capture a high speed race car (in all its glorious details) - we would need a faster shutter speed.\nNow let us imagine that we want to capture a beautiful star trail from the Himalayas. We need to capture the movement of the stars, so we would need a low shutter speed.\n\n\nISO\n\nWait, didn‚Äôt we cover everything? What is ISO?\n\nISO stands for International Organization for Standardization and it stands for sensitivity to light.\nBefore we go into ISO for digital cameras , let us revisit the old days.\n\n\n\nSource: Vintage Yashica 635\n\n\nIn the film camera ISO or ASA as it was known in those days defined the sensitivity of the film‚Äôs material to light. This is usually expressed in numbers such as 100,200,400,..1600. Now the lower the number is the less sensitive it is to light.\nWhich means in a low light environment the image would not be well exposed. Similarly if the ISO is higher, then in a low light environment it would still produce well exposed images.\n\n\n\nSource: ISO Exposure Exercise\n\n\nHowever for digital cameras ISO works differently. An image sensor is fundamentally different from a film one. Here the image is capture at a base ISO (100) always. When we select an ISO of 3200 a gain of 32X is applied to the already captured image.\nThe better the sensor the higher the tolerance of the gain.This means a good sesnor will be able to boost the image significantly without any noise, whereas a poor sensor will show noise in the image at lower values.\n\nNote: The ISO in a digital camera is applying computational photography. The sensor and chip applies gains to the image after it is captured.\n\nAperture, shutter-speed and ISO are three pillars of photography. Together they control the amount of light entering the device. Here is an image commonly known as the exposure triangle that helps us understand the relationship between these three variables.\n\n\n\nSource: The Three Elements of The Exposure Triangle\n\n\nA good photographer knows this by heart, a great photographer controls itüòé.\n\n\n\nThe Problems\n\nBut why do we need Computational Photography?\n\nEven the best of cameras have limitations. Some of them might be:\n\nCreating a small aperture is costly and time consuming. However images for constricted aperture is more aesthetic. This presents a challenge: to achieve the same quality of images using larger apertures.\nA small shutter speed for e.g 1/10 or 1/5 is realistically impossible for the human hand to keep still. Thus it is very difficult to take photographs for longer durations without a camera stand.\nNot all camera sensors are built the same. A camera sensor that will allow a high ISO value without passing any noise in the output would be immensely costly. Thus low light or night photography is completely trash in low end cameras.\n\nWith the dawn of the 21st Century science started challenging barriers and limitations. What was previously considered impossible is now one innovation away.\n\nComputational Photography aims to solve these challenges leveraging the minimal hardware requirements possible.\n\nIn the next blogpost we will look at some methods adopted by smartphones and industry giants like Google and Apple to cater Computational Photography at scale.\n\n\nLooking Back\nIn many ways photography began as an art form. The perfect instrument to capture moments. When it all began, photographs were taken and developed with care and attention in a dark room. The photographer worked hours to develop the photograph with only his memory as reference.\nWe moved from there to digital cameras that let us take photographs and visualise them instantly. The skill and dexterity of the photographer faded a little. He didn‚Äôt need a masking tape and fine toothed brush and the right mix of chemicals to bring out details.\nAnd now we arrive at the present day, photographs are no longer taken but generated. Frames are stitched together and pixels are fused by massive algorithms to bring the best version of the photograph on screen. The phtographer no longer cares about elements of photography like aperture or shutter speed.\nMaybe this is the purpose of technology - to advance science and ease our lives in the process. But great photographs have been taken even in the harshest of limitations.\nAnd perhaps that is the meaning of art - beauty even in great adversity.\n\n\nReferences\n\nComputational Photography - Wikipedia\nWhat is Computational Photography\nDefinition of ISO\nHistory of ISO\nMathemetical Expression of Noise"
  },
  {
    "objectID": "posts/2025-12-11-gwo-playground.html",
    "href": "posts/2025-12-11-gwo-playground.html",
    "title": "Interactive Grey Wolf Optimization",
    "section": "",
    "text": "This is an interactive simulation of the Grey Wolf Optimizer (GWO) algorithm attempting to solve the Rastrigin Function. The global optimum is at the center (0,0).\n\n\n\n&lt;div class=\"control-group\"&gt;\n  &lt;label&gt;Population Size: &lt;span id=\"val-pop\"&gt;30&lt;/span&gt;&lt;/label&gt;\n  &lt;input type=\"range\" id=\"popSize\" min=\"5\" max=\"100\" value=\"30\"&gt;\n&lt;/div&gt;\n&lt;div class=\"control-group\"&gt;\n  &lt;label&gt;Max Iterations: &lt;span id=\"val-iter\"&gt;500&lt;/span&gt;&lt;/label&gt;\n  &lt;input type=\"range\" id=\"maxIter\" min=\"100\" max=\"1000\" step=\"10\" value=\"500\"&gt;\n&lt;/div&gt;\n&lt;div class=\"control-group\"&gt;\n  &lt;label&gt;Speed (FPS): &lt;span id=\"val-speed\"&gt;30&lt;/span&gt;&lt;/label&gt;\n  &lt;input type=\"range\" id=\"speed\" min=\"1\" max=\"60\" value=\"30\"&gt;\n&lt;/div&gt;\n\n&lt;button id=\"restartBtn\" class=\"btn-restart\"&gt;Restart Simulation&lt;/button&gt;\n\n&lt;div class=\"stats-box\"&gt;\n  &lt;div&gt;Best Fitness: &lt;span id=\"bestScore\" style=\"color:red; font-weight:bold;\"&gt;Infinity&lt;/span&gt;&lt;/div&gt;\n  &lt;div&gt;Iteration: &lt;span id=\"currentIter\"&gt;0&lt;/span&gt;&lt;/div&gt;\n&lt;/div&gt;\n\n&lt;div style=\"margin-top:15px; font-size:0.85rem; color:#666;\"&gt;\n  &lt;strong&gt;Legend:&lt;/strong&gt;&lt;br&gt;\n  &lt;span style=\"color:red\"&gt;‚óè&lt;/span&gt; Alpha (1st)&lt;br&gt;\n  &lt;span style=\"color:orange\"&gt;‚óè&lt;/span&gt; Beta (2nd)&lt;br&gt;\n  &lt;span style=\"color:gold\"&gt;‚óè&lt;/span&gt; Delta (3rd)&lt;br&gt;\n  &lt;span style=\"color:grey\"&gt;‚óè&lt;/span&gt; Omega (Pack)\n&lt;/div&gt;\n\n\n&lt;canvas id=\"simCanvas\" width=\"500\" height=\"500\"&gt;&lt;/canvas&gt;"
  },
  {
    "objectID": "posts/2023-12-07-moe-for-dummies.html",
    "href": "posts/2023-12-07-moe-for-dummies.html",
    "title": "Mixture of Experts for Dummies",
    "section": "",
    "text": "Mixture of Experts for Dummies\nThis post is meant as a tutorial to help one get started with the basic concept of a Mixture-of-Expert. It looks at various types of MoEs and their individual nuances. Read on to get into the mix!\n\nIn the beginning‚Ä¶\nLarge Language Models (LLMs) are powerful neural networks that have achieved remarkable results in various natural language processing tasks. However, their massive size and computational complexity pose challenges for training and deployment. To address some of these challenges, Mixture of Experts (MoE) architecture has emerged as a promising technique.\n\n\nMoE, MoE?\nMoE or Mixture of Experts is a neural network architecture that divides a large model into smaller, specialized sub-models called experts. Each expert is trained to handle specific subtasks or input types. During inference, a gating network decides which expert(s) are best suited for each input, and only those experts are activated. This allows for more efficient computation and resource allocation compared to a single large model.\n\n\nHow does a MoE work?\nMoE consists of three main components: - Expert networks: These are smaller sub-models trained on specific subtasks or input types. - Gating network: This network determines which expert(s) are best suited for each input. It considers features of the input and the capabilities of each expert. - Combiner: This component aggregates the outputs from the activated experts to produce the final output of the model.\nHere‚Äôs a simplified breakdown of the MoE process:\n\nInput: The LLM receives an input (e.g., text, code, etc.).\nFeature extraction: Features are extracted from the input.\nGating network: The gating network analyzes the features and activates a small subset of experts.\nExpert processing: Each activated expert processes the input and generates its own output.\nCombining: The outputs from the activated experts are combined to produce the final output of the LLM.\n\n\\[ \\text{Output} = \\sum_{i=1}^N \\text{Expert}_i(\\text{Input}) \\cdot \\text{Gating}(i) \\]\n\n\n\n\nVanilla MoE\nA Vanilla MoE is the simplest form of the architecture; it is a simple MoE with all the Experts switched on. We can get a brief idea from the image shown here:\n\n\n\nvanilla-moe\n\n\n\n\nSparse MoE:\nImagine a team of experts working on a complex problem. Each expert has unique knowledge and skills, but it‚Äôs not efficient to involve all of them for every task.\nSparse MoE (Mixture of Experts): Google Brain proposed a solution: a network with many ‚Äúexperts,‚Äù but only a few are active for each task. This allows for a larger model capacity while saving resources.\n\n\n\nsparse-moe\n\n\nGoal: Achieve ‚Äúsingle sample single expert processing.‚Äù This means the model chooses one specific expert for each input during inference, saving computation. Example: Imagine a team of 100 experts. The model only activates 3 experts for a specific task, significantly reducing computational cost.\nDuring training, the model tends to favor ‚Äúearlier‚Äù experts, making them more likely to be chosen. This leads to only a few experts being used effectively. This is called the ‚ÄúExpert Balancing problem.‚Äù\n\n\nTransformer MoE\nWhen models reached hundreds of billions of parameters, scaling became difficult. MoE (Mixture of Experts) resurfaced as an economical and practical solution. Google‚Äôs GShard pioneered MoE integration with Transformers. Subsequent work like Switch Transformer and GLaM further improved the technique. MoE reduced LLM parameters from billions to trillions. GLaM‚Äôs architecture:\n\n\n\ntransformer-moe\n\n\n\nMoE layers (position-wise) interweave with FFN layers in the Transformer encoder and decoder.\nTop-2 routing in the Gating Network selects the two most likely experts.\n\n\n\nLifelong-MoE\nTo tackle Lifelong Learning Google released Lifelong-MoE in May 2023. The model‚Äôs Lifelong learning strategy includes the following steps: - Expand the number of Experts and the corresponding Gating dimensions. - Freeze the old Expert and the corresponding Gating dimension, and only train the new Expert. - Use the Output Regularization method to ensure that the new Expert inherits the knowledge learned in the past\n\n\nQuiz Time!\n\n\n\n\nWrapping Up‚Ä¶\nThink of MoE as a group of scientists working on a complex project. Each scientist has their own expertise and focuses on a specific task. There is also a lead scientist, who chooses which project to push and which to halt based on their features.\nThis allows the entire project to be completed more efficiently and effectively.\nMoE is a relatively new technique in the field of LLMs, so the research is voluminious and growing each day. However, its potential benefits are significant, and it is expected to play a major role in the future development of LLMs.\n\n\nReferences and Acknowledgement\n\nThis work was developed along with Aritra Roy Gosthipaty\nThe Next LLMs Development: Mixture-of-Experts with ‚Ä¶ - AIFT\nMixture of Experts-Introduction - Abdulkader Helwan\nMixture-of-Experts Meets Instruction Tuning:A Winning Combination for Large Language Models\nMemory Augmented Language Models through Mixture of Word Experts\n\n{% if page.comments %}\n\n\n\n\n\nPlease enable JavaScript to view the comments powered by Disqus.\n\n{% endif %}"
  },
  {
    "objectID": "posts/2021-09-14-why-model-decay-using-the-exponential-function.html",
    "href": "posts/2021-09-14-why-model-decay-using-the-exponential-function.html",
    "title": "Why model decay using the exponential function?",
    "section": "",
    "text": "So you have been going through mathematical models and equations for all sorts of things and everywhere you go you see this equation.\nObviously, you know why it‚Äôs used. It is the infamous exponential decay function. But you want to know why specifically this function. What is so special about an exponent that it is used to model decay.\n\\[e^{-x}\\]\nIn this blog we will learn the following:\n\nWhat is a decay function?\nWhy use exponentials?\nHow does it help us model systems?\n\nLet‚Äôs get started with some definitions first.\n\nWhat is a decay function?\nWell in simple english it means to grow old and wither away from existence.\nIn scientific terms, decay is the process of reducing an amount by a certain measure consistently over a period of time.Let us look at some examples.\n\\[f(x) = (5-x)\\]\n\n\n\ndecreasing\n\n\nIn this function, we can see that for all positive values of \\[x\\] the function decreases from 5. However, if the interval is changed and x starts from 0 and goes till \\[-\\infty\\] then the function starts increasing from 5.\nWe can play around with lots of definitions and functions to see where a function would be decreasing and where it would be strictly decreasing.\n\nA function would be called strictly decreasing in the rang \\[(a,b)\\] if\n\n\\[x_1,x_2 \\in (a,b) : x_1 &lt;x_2 \\implies f(x_1) &gt; f(x_2)\\]\n\n\nWhy use exponentials?\nFirst, let us understand what kind of data is best modeled by exponentials. The following is a table of some data points.\n\n\n\nx\ny\n\n\n\n\n10\n10\n\n\n20\n20\n\n\n30\n40\n\n\n40\n80\n\n\n\nNow as we plot this data we can see that it doubles with every iteration, compounding at a constant rate. This rate of compounding is described by \\[e^x\\].\nSo we can go as far as to say that exponential is the natural language of growth. Now, what happens when we use this same idea but reverse it.\nAgain, let us look at a table of data.\n\n\n\nx\ny\n\n\n\n\n10\n10\n\n\n20\n5\n\n\n30\n2.5\n\n\n40\n1.25\n\n\n\nThe graph for this data would be something like this:\n\n\n\ndecreasing\n\n\nThis can be modeled by the equation \\[y= e^{-x}\\]\nBut why? Why does this equation fit this data so well? To understand this better let us go back to our old friend - rate-of-change.\nNow how do we describe decay through calculus? Well, we need to take a quantity \\[N\\] and another quantity \\[x\\]. And we need to write how the rate of change of \\[N\\] varies with the rate of change of \\[x\\].\n\\[\\frac{dN}{dx}\\]\nWe can say that this rate of change may be something as simple as \\[-bN\\] where \\[b\\] is a constant.\n\\[\\frac{dN}{dx} = -bN \\\\\n\\]\nThis equation can be rewritten and solved fairly simply\n\\[\\frac{dN}{N} = -bx \\\\\nln(N) = -bx+C\\]\nSolving for the logarithm and ignoring the constant of integration we have\n\\[N(x) = N_oe^{-bx}\\]\nWhere \\[N(x)\\] is the current value of \\[N\\] with respect to \\[x\\] and \\[N_0\\] is the initial value or the starting point of \\[N\\]\n\n\nHow does it help us model systems?\nNow we know that the function \\[A(x) = A_0e^{-bx}\\] can very easily model the process of compounding decay.\nThe use of this equation in modeling real-world applications is numerous.\n\nIt is particularly useful in modelling a certain kind of decay\nIt is easy to determine when the decaying quantity would be half of its original amount. This is commonly known as half-tim.\nThe function is also easily differentiable with it‚Äôs rate of change being the same as the function itself.\n\nThe function \\[y= e^{-x}\\] is a powerful tool to have in your arsenal. But it is even more powerful when we understand when and where to use it best. Not all systems that decay gradually can be modelled using the exponential decay function, the trick is to use it selectively and use it best.\n\n\nReferences\n\nhttps://www.thoughtco.com/exponential-decay-definition-2312215#:~:text=In mathematics%2C exponential decay describes,of time that has passed.\nhttps://courses.lumenlearning.com/waymakercollegealgebra/chapter/exponential-growth-and-decay/\nhttps://mathworld.wolfram.com/DecreasingFunction.html"
  },
  {
    "objectID": "posts/2021-04-12-what-do-we-mean-when-we-talk-about-causal-inference.html",
    "href": "posts/2021-04-12-what-do-we-mean-when-we-talk-about-causal-inference.html",
    "title": "What do we mean when we talk about Causal Inference?",
    "section": "",
    "text": "So what does Causal Inference really mean? What does it mean to cause? Is Causality really as simple as understanding cause and effect? Let us attempt to first understand few of the ground rules before we play the game of Causality. \nIf you had a penny for every time you heard that line, you would probably be Bruce Wayne by now. But what does it mean? Why does correlation of two events not imply causality? What is up?\n\nAt this point you‚Äôre probably wondering, yeah I have heard about Causality a few hundred times, but do I really need to care?\n\nLet me ask you a different question then.\nHow many times have you looked at the result of your model and wondered what-if the data was something other than what I trained on. Maybe you write an algorithm that predicts the sales of comic books, and your model works really well and produces high accuracy predictions, but you need to know why. Or maybe its the opposite, your algorithm predicts completely wrong sales figures and you really need to figure out a reason for that.\nConfused? Let‚Äôs look at an example-\nSuppose you are hired by Marvel as a data scientist. There has been a recent rise in comic book sales and you need to figure out the reason so that the company can mantain the sales figures. After some data analysis you come to the conclusion that there is a direct correlation between comic book sales and disney plus subscriptions. But you still don‚Äôt have an exact reason, so you come up with some scenarios to form a hypotheses.\n\nScenario 1\n The comics display ads from disney, so obviously an increase in comic book sales causes more Disney Plus subscriptions.\n\n\nScenario 2\n Disney Plus has shows about comic book characters. New fans would like to consume more of such content. So increase in disney plus subscriptions lead to more marvel comics being bought.\n\n\nScenario 3\n Or maybe its something quite different. All Marvel Cinematic Universe movies are on Disney Plus. When a new Marvel movie comes out the hype around these characters lead to more comic book sales (and in turn more Disney Plus subscriptions).\n\nThe possibility presented in scenario 3 is what is termed as a hidden cause.\n\nEach node is a variable and each arrow shows the direction of causal connection.\n\nSuppose we build an accurate model to predict when the user will buy more comic books. But that is all that our model would do. When in reality, the actual problem statement could be better expressed by a question like-\n\nWhat would the user have done if we had done something differently?\n\nSo you might be thinking, I get it the model doesn‚Äôt always take hidden causes into account, but it still works. The predictions are still accurate.\nWell, it is actually considered really lucky to have our observed effect and causal effect in the same direction. More often than not we see the opposite in real world data.\n\nLets take a look at another example to understand this better-\nSay suppose you have now taken up employment at a food ordering app as a Data Scientist. The product designer wants to introduce a new User Interface which she believes will engage more users. She has introduced the new UI to a select few people and wants you to make sense of the data that has been gathered. You decide to judge the the Old User Interface and the new one on a common criteria, which is whether the user orders after opening the app. Lets call this the opened-and-ordered criteria.\n\n\n\n\n\n\n\n\nUI Type\nRatio of users who opened-and-ordered to total users\nPercentage\n\n\n\n\nOld UI\n20/100\n20%\n\n\nNew UI\n28/100\n28%\n\n\n\nBased on this data, it seems pretty straightforward. The new UI is the clear winner. But something very strange happens when you condition the data on high activity vs low activity users.\n\n\n\n\n\n\n\n\n\nOld UI\nNew UI\n\n\n\n\nPercentage of Opened-and-Ordered for High Activity Users\n15/80 = 25%\n14/60 = 23.33%\n\n\nPercentage of Opened-and-Ordered for Low Activity Users\n2/20 = 10%\n5/40 = 7.5%\n\n\n\nThis discrepancy of data on being modeled on different subset of the original data is called ‚ÄúSimpson‚Äôs Paradox‚Äù. Google this later. :wink:\n\n‚ÄúBut hey why does this discrepancy occur?‚Äù\n\nWell maybe, since the old UI is already tried and tested it is shown to users only at a particular time of the day, around evening when app activity is generally high. The new UI might be shown at other times of the day when the number of lower activity users who are likely to order food is actually less.\nSo the Causal diagram may look something like this:\n\nThe debate on what it means to cause something and how cause precedes effect has been going on forever. Most prominent contestants include but are not limited to -\n\nAristotle\nHume\nEinstein\nThat French guy from Matrix 3\nJudea Pearl and many more\n\nHowever sadly until recently, the science of causal inference was not considered formal mathematics or even something that could be quantified and studied.\nThis was remedied hugely by the contributions of Judea Pearl (Causal Graphical Models) and Donald Rubin (Rubin Causal Model).\nSo in conclusion, what we really learned here was that simply because two variables are correlated does not necessarily mean that one is the direct cause of the other. If we do not keep an eye out for hidden causes and their effects we can actually do more harm through our model.\nTherefore the idea of what would happen had something in the observation process been changed becomes an imperative question to ask.\nThis is called Counterfactual Thinking.\n\nCounterfactual thinking, or specifically thinking about what-if scenarios is the very heart of causal inference.\n\nSome of the ways we can answer a counterfactual question are -\n\nRandomization\nNatural Experiments\nConditioning\n\nInetrestingly as we go down the list, the methods become much harder to use. But as we go up, the methods are more foolproof and give better validation results. We will take a closer look at these and the various underlying methodologies in the next blogpost, till then keep learning and don‚Äôt stop asking the question -\n\nWhat-If?\n\n\n\n\nReferences\n\nCausal Inference in Online Systems by Amit Sharma\nAn awesome playlist for Causal Learning"
  },
  {
    "objectID": "posts/2021-08-10-a-brief-introduction-to-do-calculus.html",
    "href": "posts/2021-08-10-a-brief-introduction-to-do-calculus.html",
    "title": "A Brief Introduction to Do-Calculus",
    "section": "",
    "text": "Welcome back to Part 3 of The Causal Blog. The previous two parts introduced us to the world of causal inference and what are the various methodologies involved. You can find them right here.\nIn this part we will be discussing a very popular and useful method known as the do-calculus developed by Judea Pearl in 1995. It was developed to propose a foolproof methodology for identification of causal effects in non parametric models.\nWell, that‚Äôs a mouthful. What do we mean by that?\nIn simple words, this means to identify the effect or effects for a particular cause from data that is continuous rather than having discrete values.\nWe have learned in the previous blogs that it is impossible to do Causal Inference without having some form of intervention on the provided data. To facilitate this do-calculus introduces a mathematical operator called \\(do(x)\\) which simulates intervention by removing certain functions from the model and by replacing them with a constant \\(X=x\\). To understand how this plays out we will first have to look at some of the definitions introduced by the authors.\n\nDefinitions and Rules\n\n1. Definition 1\nThe probability distribution of the outcome \\[Y\\] after the intervention is given by the equation:\n\\[\nP_M(y \\mid do(x))=P_{M_x}(y)\n\\]\nwhere the distribution of the outcome \\[Y\\] is defined as the probability assigned by the model \\[M_x\\] to each outcome level \\[Y=y\\]\n\n\n2. Definition 2\nThis part talks about when and under what conditions a causal query( whether a variable or a group of variables is the cause for a given effect or not) is identifiable.\nGiven a set of assumptions \\(A\\) satisfy two fully specified models \\[M_1\\] and \\[M_2\\], the following is the criteria for identifiability:\n\\[P(M_1) = P(M_2) =&gt; Q(M_1) = Q(M_2)\\]\nThis means that whatever the details of the models are, if the distribution of the two models given the same set of assumptions \\(A\\) are equal then it follows that the causal query for the two models should also be equal. This can be extended to mean that a causal query, under such circumstances can be expressed in terms of the parameters of \\(P\\).\n\n\n\nThe 3 Rules of do-calculus\nNow that we have learned about the definitions of do-calculus let us familiarise ourselves with the three rules that govern the mathematics of do-calculus. But first we need to understand the necessity of these rules.\nIn the previous section we learned under what conditions a causal query will be identifiable and we also saw how to formulate an expression in terms of a do-expression, e.g \\[P_M(y \\mid do(x))=P_{M_x}(y)\\]. So when a causal query is given to us in the form of do-expression there are actual mathematical steps that can be taken to resolve it and find out whether the query is identifiable or not.\nConsider the following directed acyclic graph \\[G\\] where \\[X\\],\\[Y\\],\\[Z\\] and \\[W\\] are arbitrary disjoint nodes. \\[G_{\\bar{X}}\\] is the manipulated graph where all incoming edges to \\[X\\] have been removed.\n\n\n\nexample1\n\n\nSimilarly \\[G_{\\underline{X}}\\] is the manipulated graph where all outgoing edges to \\[X\\] have been removed.\n\n\n\nexample2\n\n\nAnother useful notation to get familiarised with is the concept of d-separation (\\[\\perp\\perp\\]). In very simple words, given the graph \\[a \\rightarrow c \\rightarrow b\\] the expression \\[ a \\perp\\perp b \\mid c\\] means that a is conditionally independent of b given c. To understand d-separation in a more detailed manner have a look at this single page explanation.\n\nRule 1: Insertion/deletion of observation\n\\[P(y \\mid do(x),z,w)\\] = \\[P(y \\mid do(x),w)\\] if \\[(Y \\perp\\perp Z \\mid X,W)\\] for \\[G_{\\bar{X}}\\]\nThis means that if \\[Y\\] is d-separated from \\[Z\\] given \\[X\\] and \\[W\\] then the expression of probability \\[P(y \\mid do(x),z,w)\\] resolves to \\[P(y \\mid do(x),w)\\]. An easier way to understand this is by getting rid of the do-operators on both the sides of the equality sign.\n\\[P(y \\mid z,w)\\] = \\[P(y \\mid w)\\] if \\[(Y \\perp\\perp Z \\mid W)\\] for \\[G\\]\nThe above expression simply implies conditional independence within the variables in the distribution given regular d-separation.\n\n\nRule 2: Action/observation exchange\n\\[P(y \\mid do(x),do(z),w)\\] = \\[P(y \\mid do(x),z,w)\\] if \\[(Y \\perp\\perp Z \\mid X,W)\\] for \\[G_{\\bar{X}\\underline{Z}}\\]\nTo simplify the expression above let us again remove \\(do(x)\\) or consider \\(X\\) to be an empty set.\n\\[P(y \\mid do(z),w)\\] = \\[P(y \\mid z,w)\\] if \\[(Y \\perp\\perp Z \\mid W)\\] for \\[G_{\\underline{Z}}\\]\nThis expression refers to the backdoor-adjustment criteria that we saw in chapter 2. Therefore this rule gives us the interventional distribution for the backdoor adjustment criteria.\n\n\nRule 3: Insertion/deletion of action\n\\[P(y \\mid do(x),do(z),w)\\] = \\[P(y \\mid do(x),w)\\] if \\[(Y \\perp\\perp Z \\mid X,W)\\] for \\[G_{\\bar{X}\\bar{Z(W)}}\\]\nwhere \\[Z(W)\\] is the set of \\[Z\\] nodes that are not ancestors of any \\[W\\] node in \\[G_{\\bar{X}}\\].\nAgain for the sake of simplification let us remove the \\(do(x)\\) operator from the above expression.\n\\[P(y \\mid do(z),w)\\] = \\[P(y \\mid w)\\] if \\[(Y \\perp\\perp Z \\mid W)\\] for \\[G_{\\bar{Z(W)}}\\]\nNow let us take a moment to pause here and really understand what this means. On the paper it means that we do can remove the intervention term \\[do(z)\\] provided there is no causal association flowing from Z to Y \\[(Y \\perp\\perp Z \\mid W)\\] in the graph \\[G_{\\bar{Z(W)}}\\].\nBut that‚Äôs not all. We have a strange term called Z(W) which doesn‚Äôt quite fit in.\nThe simplified expression should have been :\n\\[P(y \\mid do(z),w)\\] = \\[P(y \\mid w)\\] if \\[(Y \\perp\\perp Z \\mid W)\\] for \\[G_{\\bar{Z}}\\]\nWhere removal of incoming edges to Z should result in d-separation of Y and Z and no causal association should flow from Z to Y. However instead of this simple term we end up with an expression containing Z(W). To understand this better let us consider the graph below:\n\n\n\nexample3\n\n\nNow the intuitive idea is to remove incoming edges to Z (\\[G_{\\bar{Z}}\\]). But if we do that then we risk changing the distribution of Y altogether through the backdoor path consisting of U and V.\nInstead what we can do is take a sub-node of Z say \\[Z_2\\] which is not an ancestor of any node in W and then remove all the incoming edges to it (\\[G_{\\bar{Z_2}}\\]). This is shown in the figure below.\n\n\n\nexample4\n\n\n\n\n\nConclusion\nThe rules and definitions of do-calculus provide a general structure for identifying Causal queries. The final query Q should be free of any do-operator, this can be achieved by repeatedly applying the three rules. It is also complete, meaning if there exists a Causal Query Q which is identifiable then it can be identified using do-calculus.\nThis chapter was aimed at introducing do-calculus very briefly and laying down the rules of the game. The idea is to not intimidate any newcomer with a whole lot of mathematical jargon but to provide an insight into an essentially simple yet powerful framework for causal inference.\n\n\nReferences\n\nThe Do-Calculus Revisited by Judea Pearl\nPearl‚Äôs Do-Calculus by Brady Neal"
  },
  {
    "objectID": "posts/2024-12-29-notes-on-technical-writing.html",
    "href": "posts/2024-12-29-notes-on-technical-writing.html",
    "title": "Notes on Technical Writing",
    "section": "",
    "text": "Notes on Technical Writer\nSince the very start of my career, I have viewed technical writing as more than just a means of communication‚Äîit‚Äôs a powerful tool for both teaching and learning.\nThe process of organizing thoughts, and presenting them clearly often benefits the writer as much, if not more, than the reader.\nIn this post, I aim to capture some of the lessons I‚Äôve learned, the tools I rely on, and the principles I follow to make technical writing a meaningful and impactful craft.\n\n\nGeneral Rules of the Trade\n\n1. Clarity Is Key\nTechnical writing should simplify, not complicate. Follow these golden rules: - Break down instructions into small, digestible steps. - Use links, screenshots, and examples to guide the reader. - Include the expected outcomes for every process.\n\n\n2. T-Shaped Approach for Deep Dives\nWhen explaining a topic: - First, provide an overview to cover the breadth of the subject. - Then, choose an aspect to dive into, offering depth and detail. - Use Google‚Äôs Style Guide for consistency.\nCore Techniques from Google‚Äôs Style Guide: - Write in the active voice to clarify actions and actors. - Use numbered lists for sequential steps and bulleted lists for non-sequential points. - Write in the second person, addressing the reader as ‚Äúyou.‚Äù - Place conditions before instructions, not after (e.g., If the file exists, then delete it). - Format code or technical terms using code font.\n\n\n\n3. Understand and Think Like Your Audience\n\nWho is your audience? Create personas with attributes such as:\n\nRole: QA Tester, Developer, or System Administrator.\nGoal: Restore a database, deploy an application.\nKnowledge Base: Familiarity with Python, command-line tools, or Linux.\n\nAdjust for inclusivity: Avoid jargon unless your audience is well-versed in it. Provide definitions for unfamiliar terms and include links to additional resources.\nStrike a balance: Avoid over-narrowing your focus to one persona. Broaden where possible to be inclusive of diverse readers.\n\n\n\n\n4. Write, Review, Improve\n\nRead it aloud: This ensures conversational and engaging writing. If sentences feel awkward, rephrase them.\nTake breaks: Step away from your draft to gain fresh perspectives.\nChange context: Print your draft or change fonts for a new perspective.\nSeek peer feedback: Like code, writing benefits from constructive reviews. Ensure your reviewers understand your style guide.\n\n\n\n\n5. Code Integration Best Practices\n\nAlways include line numbers when providing code examples and refer to them in your explanations.\nOffer a link to the full code (e.g., GitHub or Gist) at the beginning of the document.\nUse visual tools like Slides Code Highlighter to make code stand out in presentations.\n\n\n\n\n6. Use LLMs as a Tool (only a tool)\nLeverage Large Language Models (LLMs) such as ChatGPT, Claude and others to: - Edit and refine your drafts. - Refactor sections for clarity. - Never use it to think for you!\n\n\n\n\nTools to Elevate Your Writing\nHere‚Äôs a curated list of tools (that I personally use) to boost your technical writing:\n\nSlides Code Highlighter\nHighlight code elegantly in Google Slides.\nManim\nCreate high-quality technical videos and animations.\nDraw.io\nCraft polished technical diagrams.\nGrammarly\nRefine grammar, spelling, and readability.\nHemingway App\nAssess readability and improve sentence structure.\nWrite the Docs\nJoin a global community for resources, workshops, and support.\n\n\n\n\nParting Thoughts\n\n1. Prioritize the Reader\nYour audience is the heart of your writing. Focus on their needs rather than how much information you can cram in.\n\n\n2. Simplicity Is Hard\n\nKnow your audience‚Äôs knowledge level.\n\nUse clear, concise language.\n\nStructure content logically, with easy-to-follow steps.\n\n\n\n3. Community helps, a lot\nTechnical writing is not a solitary journey. Engage with communities like Write the Docs to grow, learn, and refine your craft.\nMastering technical writing is a journey, but with practice and empathy for your audience, you can transform your documentation into a tool that empowers and enlightens its readers. Keep writing, keep improving, and most importantly‚Äîkeep caring.\n\n\n\n\nReferences\n\nGoogle Technical Writing\n\nReddit: Becoming a Technical Writer\n\nSheCodeAfrica: A Guide to Technical Writing"
  },
  {
    "objectID": "posts/2023-07-24-understanding-augmix.html",
    "href": "posts/2023-07-24-understanding-augmix.html",
    "title": "Understanding AugMix",
    "section": "",
    "text": "TL;DR\nIn machine learning, we use a set of data (known as the ‚Äútraining‚Äù data) to teach an algorithm how to solve a task. In this context, we‚Äôre talking about deep neural networks which are a kind of machine learning algorithm designed to classify images. An image classifier‚Äôs job is to look at an image and decide which category it belongs to, like identifying whether a photo is of a cat or a dog.\nWhen the algorithm is learning, it adjusts itself to perform well on the training data. It‚Äôs then tested on separate ‚Äútest‚Äù data to see how well it has learned. Ideally, the training and test data should be very similar (identically distributed) in nature. For example, if the task is to distinguish between cats and dogs, and if all the images in the training set are taken in broad daylight, we expect the test set also to have images taken in similar conditions.\nHowever, in real-world scenarios, there can be a mismatch between the training and test data. This could be due to a variety of factors like the lighting conditions, the angle of the camera, or the breed of the dogs and cats in the images. When this mismatch happens, the accuracy of the image classifier can drop significantly because it has not encountered these conditions during training.\nMost current techniques for training these algorithms struggle when the test data is different from the training data in ways they didn‚Äôt anticipate. This is where the technique called ‚ÄúAUGMIX‚Äù comes in.\nAUGMIX is a method that helps improve the robustness of the model. Robustness in this context refers to the model‚Äôs ability to maintain accuracy even when the test data differs from the training data in unexpected ways.\nHere‚Äôs how AUGMIX works: it applies a mix of augmentations (slight modifications) to the images in the training data. These might include things like adjusting the brightness or contrast, rotating the image, or zooming in slightly. By doing this, AUGMIX creates a wide range of scenarios the model might encounter. It‚Äôs like showing the model not only pictures of cats and dogs taken in the day but also at twilight, from different angles, of different breeds, etc.\nThis helps in two ways:\n\nIt makes the model more robust because it has seen a wider range of image conditions during training.\nIt helps the model to provide better uncertainty estimates. Uncertainty estimates tell us how confident the model is about its predictions. A well-calibrated model knows when it‚Äôs likely to be wrong, which is very useful when decisions based on these predictions have significant consequences.\n\n‚Ä¶ (content continues, all image references updated to /assets/images/ as needed) ‚Ä¶"
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Ritwik Raha",
    "section": "",
    "text": "Hi, I‚Äôm Ritwik Raha, Machine Learning Engineer at Google by job title, professional neural network whisperer by life choice. I spend my time thinking about post-training, RL, and whether LLMs can be taught to reason, or at least fake it convincingly.\nWhen I‚Äôm not wrangling models, I‚Äôm either making semi-coherent ML videos on YouTube or committing mild acts of chaos on X under the noble banner of shitposting.\nThis site is my corner of the internet, equal parts portfolio, thought-dump, and polite flex.\nOh, and I am also a very human artist, invested in ‚ÄúArtists against AI‚Äù movement. Yeah I know, paradox! Go check out some of my artwork here.\n\n\n\n\nWork and News\n\n\n\n14 Jan 2025 ‚Äî Joined Google as a MLE\n\n\n22 Apr 2023 ‚Äî ML and Vibes as a GDE in ML (Keras)\n\n\n6 Feb 2022 ‚Äî Joined PyImageSearch as a MLE\n\n\n6 Feb 2021 ‚Äî Joined TCS as a MLE\n\n\n20 Jan 2020 ‚Äî Published papers in ICCE 2020\n\n\n20 Jul 2020 ‚Äî Graduated as an Instrumentation Engineer\n\n\n\n\n\nTalks\n\n\nAI Planet - LLM Bootcamp\nML Paper Reading Club Coimbatore - ResNets\nKeras Community Day Kolkata - Keras Philosophy\nKeras Community Day Durg - Keras Philosophy\nKeras - The LEGO of Framework\nDecoding DETR - TFUG Mumbai\nA Guide to ML Workflows with JAX - TFUG Kolkata\nLearning JAX in 2023 - JAX‚Äôs Power Tools\nIntroduction to Neural Radiance Fields - NYTFUG\nA Deep Dive into Transformers - PyImageSearch\nNeural Machine Translation - PyImageSearch\nIntroduction to RNNs - PyImageSearch\nEnhancing Image Resolution with GANs - PyImageSearch\nOpenCV and Deep Learning Tutorial - PyImageSearch\nIntroduction to Deep Learning - PyImageSearch\nImage Fusion with WOA-PCNN - ICCE 2020\nCausality Analysis of Emotional States from EEG Response - ICCE 2020\nIntro to ML with DSC NSEC\n\n\n\n\nTutorials\n\n\nRecent Deep Dives\n\nCan we really scale RL?\nDDPM Explained for Dummies\nChoosing between SigLIP and CLIP for Language-Image Pretraining\nUnderstanding PaLI-Gemma in 50 Minutes or Less\n\n\n\nPaper Breakdowns\n\nDETR Breakdown Part 1\nDETR Breakdown Part 2\nDETR Breakdown Part 3\n\n\n\nJAX Guide\n\nLearning JAX in 2023: Part 3\nLearning JAX in 2023: Part 2\nLearning JAX in 2023: Part 1\n\n\n\nComputer Vision\n\nFocal Modulation: A replacement for Self-Attention - Keras Example\nA Vision Transformer without Attention - Keras Example\nNeural Style Transfer with AdaIN- Keras Example\nBreaking down Neural Radiance Fields - Part 1\nBreaking down Neural Radiance Fields - Part 2\nBreaking down Neural Radiance Fields - Part 3\n3D volumetric rendering with NeRF- Keras Example\nImage Segmentation using Whale Optimization Algorithm\nImage Compression using SVD\nFace Swapping using OpenCV\nCreating a Potrait mode with Open CV\nA brief history of Edge Detection\nDenoising images the Matlab Way\n\n\n\nNLP\n\nIntroduction to RNNs with TensorFlow and Keras\nLong Short-Term Memory Networks\nNeural Machine Translation\nNeural Machine Translation with Bahdanau‚Äôs Attention Using TensorFlow and Keras\nNeural Machine Translation with Luong‚Äôs Attention Using TensorFlow and Keras\nA Deep Dive into Transformers with TensorFlow and Keras: Part 3\nA Deep Dive into Transformers with TensorFlow and Keras: Part 2\nA Deep Dive into Transformers with TensorFlow and Keras: Part 1\n\n\n\nHitchhiker‚Äôs Guide to‚Ä¶\n\nWhat is Keras Core?\nA Hello World to Deep Learning in Matlab\nAutomatic Differentiation Part 1: Understanding the Math\nAutomatic Differentiation Part 2: Implementation Using Micrograd\n\n\n\n\n\nEducation\nSome of the formal and slightly informal education that I have recieved.\n\nGraduation - B.Tech Electronics and Instrumentation, Netaji Subhash Engg. College 2016-2020\nHigh School - Sri Aurobindo Institute of Education, 2014- 2016\nSchool - Sri Aurbindo Institte of Education, 2009-2014\n\n\n\nResearch\nThe following are the links to some of my research publications.\n\nR. Raha, A. Sengupta and A. Saha, ‚ÄúCausality Analysis of Emotional States from EEG Response,‚Äù 2020 IEEE 1st International Conference for Convergence in Engineering (ICCE), Kolkata, India, 2020, pp.¬†410-415, doi: 10.1109/ICCE50343.2020.9290546.\nR. Raha, A. Sengupta and S. Dhabal, ‚ÄúMedical Image Fusion using PCNN Optimized by Whale Optimization Algorithm,‚Äù 2020 IEEE 1st International Conference for Convergence in Engineering (ICCE), Kolkata, India, 2020, pp.¬†374-378, doi: 10.1109/ICCE50343.2020.9290504.\n\nGoogle Scholar Profile"
  }
]