{"title":"A Brief Introduction to Do-Calculus","markdown":{"yaml":{"title":"A Brief Introduction to Do-Calculus","date":"2021-08-10","author":"Ritwik Raha","tags":["causality"],"image":"/assets/images/3post/incoming-to-x.jpg"},"headingText":"Definitions and Rules","containsRefs":false,"markdown":"\n\nWelcome back to Part 3 of The Causal Blog. The previous two parts introduced us to the world of causal inference and what are the various methodologies involved. You can find them right [here](/causal-blog-1).\n\nIn this part we will be discussing a very popular and useful method known as the `do-calculus` developed by Judea Pearl in 1995. It was developed to propose a foolproof methodology for identification of causal effects in non parametric models.\n\nWell, that's a mouthful. What do we mean by that?\n\nIn simple words, this means to identify the effect or effects for a particular cause from data that is continuous rather than having discrete values.\n\nWe have learned in the previous blogs that it is impossible to do Causal Inference without having some form of intervention on the provided data. To facilitate this `do-calculus` introduces a mathematical operator called $do(x)$ which simulates intervention by removing certain functions from the model and by replacing them with a constant $X=x$. To understand how this plays out we will first have to look at some of the definitions introduced by the authors.\n\n\n#### 1. Definition 1\n\nThe probability distribution of the outcome $$Y$$ after the intervention is given by the equation:\n\n$$\nP_M(y \\mid do(x))=P_{M_x}(y)\n$$\n\nwhere the distribution of the outcome $$Y$$ is defined as the probability assigned by the model $$M_x$$ to each outcome level $$Y=y$$\n\n#### 2. Definition 2\n\nThis part talks about when and under what conditions a causal query( whether a variable or a group of variables is the cause for a given effect or not) is identifiable.\n\nGiven a set of assumptions $A$ satisfy two fully specified models $$M_1$$ and $$M_2$$, the following is the criteria for identifiability:\n\n$$P(M_1) = P(M_2) => Q(M_1) = Q(M_2)$$\n\nThis means that whatever the details of the models are, if the distribution of the two models given the same set of assumptions $A$ are equal then it follows that the causal query for the two models should also be equal. This can be extended to mean that a causal query, under such circumstances can be expressed in terms of the parameters of $P$.\n\n### The 3 Rules of do-calculus\n\nNow that we have learned about the definitions of `do-calculus` let us familiarise ourselves with the three rules that govern the mathematics of `do-calculus`. But first we need to understand the necessity of these rules. \n\nIn the previous section we learned under what conditions a causal query will be identifiable and we also saw how to formulate an expression in terms of a do-expression, e.g $$P_M(y \\mid do(x))=P_{M_x}(y)$$. So when a causal query is given to us in the form of do-expression there are actual mathematical steps that can be taken to resolve it and find out whether the query is identifiable or not.\n\nConsider the following directed acyclic graph $$G$$ where $$X$$,$$Y$$,$$Z$$ and $$W$$ are arbitrary disjoint nodes. $$G_{\\bar{X}}$$ is the manipulated graph where all incoming edges to $$X$$ have been removed.\n\n![example1](/assets/images/3post/incoming-to-x.jpg)\n\nSimilarly $$G_{\\underline{X}}$$ is the manipulated graph where all outgoing edges to $$X$$ have been removed.\n\n![example2](/assets/images/3post/outgoing-from-x.jpg \"Removing the outgoing edges from X\")\n\nAnother useful notation to get familiarised with is the concept of d-separation ($$\\perp\\perp$$). In very simple words, given the graph $$a \\rightarrow c \\rightarrow b$$ the expression $$ a \\perp\\perp b \\mid c$$ means that a is conditionally independent of b given c.\nTo understand d-separation in a more detailed manner have a look at this single page [explanation](http://bayes.cs.ucla.edu/BOOK-2K/d-sep.html#:~:text=d%2Dseparation%20is%20a%20criterion,ness%22%20or%20%22separation%22.).\n\n#### Rule 1: Insertion/deletion of observation\n\n$$P(y \\mid do(x),z,w)$$ = $$P(y \\mid do(x),w)$$ if $$(Y \\perp\\perp Z \\mid X,W)$$ for $$G_{\\bar{X}}$$\n\nThis means that if $$Y$$ is d-separated from $$Z$$ given $$X$$ and $$W$$ then the expression of probability $$P(y \\mid do(x),z,w)$$ resolves to $$P(y \\mid do(x),w)$$. An easier way to understand this is by getting rid of the do-operators on both the sides of the equality sign.\n\n$$P(y \\mid z,w)$$ = $$P(y \\mid w)$$ if $$(Y \\perp\\perp Z \\mid W)$$ for $$G$$\n\nThe above expression simply implies conditional independence within the variables in the distribution given regular d-separation.\n\n#### Rule 2: Action/observation exchange\n\n$$P(y \\mid do(x),do(z),w)$$ = $$P(y \\mid do(x),z,w)$$ if $$(Y \\perp\\perp Z \\mid X,W)$$ for $$G_{\\bar{X}\\underline{Z}}$$\n\nTo simplify the expression above let us again remove $do(x)$ or consider $X$ to be an empty set.\n\n$$P(y \\mid do(z),w)$$ = $$P(y \\mid z,w)$$ if $$(Y \\perp\\perp Z \\mid W)$$ for $$G_{\\underline{Z}}$$\n\nThis expression refers to the backdoor-adjustment criteria that we saw in chapter 2. Therefore this rule gives us the interventional distribution for the backdoor adjustment criteria.\n\n\n#### Rule 3: Insertion/deletion of action\n\n$$P(y \\mid do(x),do(z),w)$$ = $$P(y \\mid do(x),w)$$ if $$(Y \\perp\\perp Z \\mid X,W)$$ for $$G_{\\bar{X}\\bar{Z(W)}}$$\n\nwhere $$Z(W)$$ is the set of $$Z$$ nodes that are not ancestors of any $$W$$ node in $$G_{\\bar{X}}$$.\n\nAgain for the sake of simplification let us remove the $do(x)$ operator from the above expression.\n\n$$P(y \\mid do(z),w)$$ = $$P(y \\mid w)$$ if $$(Y \\perp\\perp Z \\mid W)$$ for $$G_{\\bar{Z(W)}}$$\n\nNow let us take a moment to pause here and really understand what this means. On the paper it means that we do can remove the intervention term $$do(z)$$ provided there is no causal association flowing from Z to Y $$(Y \\perp\\perp Z \\mid W)$$ in the graph $$G_{\\bar{Z(W)}}$$.\n\nBut that's not all. We have a strange term called Z(W) which doesn't quite fit in.\n\nThe simplified expression should have been :\n\n$$P(y \\mid do(z),w)$$ = $$P(y \\mid w)$$ if $$(Y \\perp\\perp Z \\mid W)$$ for $$G_{\\bar{Z}}$$\n\nWhere removal of incoming edges to Z should result in d-separation of Y and Z and no causal association should flow from Z to Y. However instead of this simple term we end up with an expression containing Z(W). To understand this better let us consider the graph below:\n\n![example3](/assets/images/3post/collider-1.jpg \"A sample graph\")\n\nNow the intuitive idea is to remove incoming edges to Z ($$G_{\\bar{Z}}$$). But if we do that then we risk changing the distribution of Y altogether through the backdoor path consisting of U and V.\n\nInstead what we can do is take a sub-node of Z say $$Z_2$$ which is not an ancestor of any node in W and then remove all the incoming edges to it ($$G_{\\bar{Z_2}}$$). This is shown in the figure below.\n\n![example4](/assets/images/3post/collider-2.jpg \"Incoming edges removed from Z2\")\n\n\n### Conclusion\n\nThe rules and definitions of do-calculus provide a general structure for identifying Causal queries. The final query Q should be free of any do-operator, this can be achieved by repeatedly applying the three rules. It is also complete, meaning if there exists a Causal Query Q which is identifiable then it can be identified using do-calculus.\n\nThis chapter was aimed at introducing do-calculus very briefly and laying down the rules of the game. The idea is to not intimidate any newcomer with a whole lot of mathematical jargon but to provide an insight into an essentially simple yet powerful framework for causal inference.\n\n### References\n\n- [The Do-Calculus Revisited by Judea Pearl](https://fermatslibrary.com/p/ebe0e889)\n- [Pearl's Do-Calculus by Brady Neal](https://www.youtube.com/watch?v=M-mF6bXlxHI) ","srcMarkdownNoYaml":"\n\nWelcome back to Part 3 of The Causal Blog. The previous two parts introduced us to the world of causal inference and what are the various methodologies involved. You can find them right [here](/causal-blog-1).\n\nIn this part we will be discussing a very popular and useful method known as the `do-calculus` developed by Judea Pearl in 1995. It was developed to propose a foolproof methodology for identification of causal effects in non parametric models.\n\nWell, that's a mouthful. What do we mean by that?\n\nIn simple words, this means to identify the effect or effects for a particular cause from data that is continuous rather than having discrete values.\n\nWe have learned in the previous blogs that it is impossible to do Causal Inference without having some form of intervention on the provided data. To facilitate this `do-calculus` introduces a mathematical operator called $do(x)$ which simulates intervention by removing certain functions from the model and by replacing them with a constant $X=x$. To understand how this plays out we will first have to look at some of the definitions introduced by the authors.\n\n### Definitions and Rules \n\n#### 1. Definition 1\n\nThe probability distribution of the outcome $$Y$$ after the intervention is given by the equation:\n\n$$\nP_M(y \\mid do(x))=P_{M_x}(y)\n$$\n\nwhere the distribution of the outcome $$Y$$ is defined as the probability assigned by the model $$M_x$$ to each outcome level $$Y=y$$\n\n#### 2. Definition 2\n\nThis part talks about when and under what conditions a causal query( whether a variable or a group of variables is the cause for a given effect or not) is identifiable.\n\nGiven a set of assumptions $A$ satisfy two fully specified models $$M_1$$ and $$M_2$$, the following is the criteria for identifiability:\n\n$$P(M_1) = P(M_2) => Q(M_1) = Q(M_2)$$\n\nThis means that whatever the details of the models are, if the distribution of the two models given the same set of assumptions $A$ are equal then it follows that the causal query for the two models should also be equal. This can be extended to mean that a causal query, under such circumstances can be expressed in terms of the parameters of $P$.\n\n### The 3 Rules of do-calculus\n\nNow that we have learned about the definitions of `do-calculus` let us familiarise ourselves with the three rules that govern the mathematics of `do-calculus`. But first we need to understand the necessity of these rules. \n\nIn the previous section we learned under what conditions a causal query will be identifiable and we also saw how to formulate an expression in terms of a do-expression, e.g $$P_M(y \\mid do(x))=P_{M_x}(y)$$. So when a causal query is given to us in the form of do-expression there are actual mathematical steps that can be taken to resolve it and find out whether the query is identifiable or not.\n\nConsider the following directed acyclic graph $$G$$ where $$X$$,$$Y$$,$$Z$$ and $$W$$ are arbitrary disjoint nodes. $$G_{\\bar{X}}$$ is the manipulated graph where all incoming edges to $$X$$ have been removed.\n\n![example1](/assets/images/3post/incoming-to-x.jpg)\n\nSimilarly $$G_{\\underline{X}}$$ is the manipulated graph where all outgoing edges to $$X$$ have been removed.\n\n![example2](/assets/images/3post/outgoing-from-x.jpg \"Removing the outgoing edges from X\")\n\nAnother useful notation to get familiarised with is the concept of d-separation ($$\\perp\\perp$$). In very simple words, given the graph $$a \\rightarrow c \\rightarrow b$$ the expression $$ a \\perp\\perp b \\mid c$$ means that a is conditionally independent of b given c.\nTo understand d-separation in a more detailed manner have a look at this single page [explanation](http://bayes.cs.ucla.edu/BOOK-2K/d-sep.html#:~:text=d%2Dseparation%20is%20a%20criterion,ness%22%20or%20%22separation%22.).\n\n#### Rule 1: Insertion/deletion of observation\n\n$$P(y \\mid do(x),z,w)$$ = $$P(y \\mid do(x),w)$$ if $$(Y \\perp\\perp Z \\mid X,W)$$ for $$G_{\\bar{X}}$$\n\nThis means that if $$Y$$ is d-separated from $$Z$$ given $$X$$ and $$W$$ then the expression of probability $$P(y \\mid do(x),z,w)$$ resolves to $$P(y \\mid do(x),w)$$. An easier way to understand this is by getting rid of the do-operators on both the sides of the equality sign.\n\n$$P(y \\mid z,w)$$ = $$P(y \\mid w)$$ if $$(Y \\perp\\perp Z \\mid W)$$ for $$G$$\n\nThe above expression simply implies conditional independence within the variables in the distribution given regular d-separation.\n\n#### Rule 2: Action/observation exchange\n\n$$P(y \\mid do(x),do(z),w)$$ = $$P(y \\mid do(x),z,w)$$ if $$(Y \\perp\\perp Z \\mid X,W)$$ for $$G_{\\bar{X}\\underline{Z}}$$\n\nTo simplify the expression above let us again remove $do(x)$ or consider $X$ to be an empty set.\n\n$$P(y \\mid do(z),w)$$ = $$P(y \\mid z,w)$$ if $$(Y \\perp\\perp Z \\mid W)$$ for $$G_{\\underline{Z}}$$\n\nThis expression refers to the backdoor-adjustment criteria that we saw in chapter 2. Therefore this rule gives us the interventional distribution for the backdoor adjustment criteria.\n\n\n#### Rule 3: Insertion/deletion of action\n\n$$P(y \\mid do(x),do(z),w)$$ = $$P(y \\mid do(x),w)$$ if $$(Y \\perp\\perp Z \\mid X,W)$$ for $$G_{\\bar{X}\\bar{Z(W)}}$$\n\nwhere $$Z(W)$$ is the set of $$Z$$ nodes that are not ancestors of any $$W$$ node in $$G_{\\bar{X}}$$.\n\nAgain for the sake of simplification let us remove the $do(x)$ operator from the above expression.\n\n$$P(y \\mid do(z),w)$$ = $$P(y \\mid w)$$ if $$(Y \\perp\\perp Z \\mid W)$$ for $$G_{\\bar{Z(W)}}$$\n\nNow let us take a moment to pause here and really understand what this means. On the paper it means that we do can remove the intervention term $$do(z)$$ provided there is no causal association flowing from Z to Y $$(Y \\perp\\perp Z \\mid W)$$ in the graph $$G_{\\bar{Z(W)}}$$.\n\nBut that's not all. We have a strange term called Z(W) which doesn't quite fit in.\n\nThe simplified expression should have been :\n\n$$P(y \\mid do(z),w)$$ = $$P(y \\mid w)$$ if $$(Y \\perp\\perp Z \\mid W)$$ for $$G_{\\bar{Z}}$$\n\nWhere removal of incoming edges to Z should result in d-separation of Y and Z and no causal association should flow from Z to Y. However instead of this simple term we end up with an expression containing Z(W). To understand this better let us consider the graph below:\n\n![example3](/assets/images/3post/collider-1.jpg \"A sample graph\")\n\nNow the intuitive idea is to remove incoming edges to Z ($$G_{\\bar{Z}}$$). But if we do that then we risk changing the distribution of Y altogether through the backdoor path consisting of U and V.\n\nInstead what we can do is take a sub-node of Z say $$Z_2$$ which is not an ancestor of any node in W and then remove all the incoming edges to it ($$G_{\\bar{Z_2}}$$). This is shown in the figure below.\n\n![example4](/assets/images/3post/collider-2.jpg \"Incoming edges removed from Z2\")\n\n\n### Conclusion\n\nThe rules and definitions of do-calculus provide a general structure for identifying Causal queries. The final query Q should be free of any do-operator, this can be achieved by repeatedly applying the three rules. It is also complete, meaning if there exists a Causal Query Q which is identifiable then it can be identified using do-calculus.\n\nThis chapter was aimed at introducing do-calculus very briefly and laying down the rules of the game. The idea is to not intimidate any newcomer with a whole lot of mathematical jargon but to provide an insight into an essentially simple yet powerful framework for causal inference.\n\n### References\n\n- [The Do-Calculus Revisited by Judea Pearl](https://fermatslibrary.com/p/ebe0e889)\n- [Pearl's Do-Calculus by Brady Neal](https://www.youtube.com/watch?v=M-mF6bXlxHI) "},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":false,"output-file":"2021-08-10-a-brief-introduction-to-do-calculus.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","title":"A Brief Introduction to Do-Calculus","date":"2021-08-10","author":"Ritwik Raha","tags":["causality"],"image":"/assets/images/3post/incoming-to-x.jpg"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}