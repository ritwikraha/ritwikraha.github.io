{"title":"What is Computational Photography","markdown":{"yaml":{"title":"What is Computational Photography","date":"2022-01-18","author":"Ritwik Raha","tags":["math","image-processing"],"image":"/assets/images/computational-1.png"},"headingText":"TL;DR","containsRefs":false,"markdown":"\n\n> Computational photography refers to digital image capture and processing techniques that use digital computation instead of optical processes. - [Wikipedia](https://en.wikipedia.org/wiki/Computational_photography)\n\n<figure>\n  <img src=\"/assets/images/6post/apple.jpeg\" alt=\"image fusion\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"https://www.eoshd.com/comments/topic/38399-lets-discuss-computational-photography/\">Apple Computational Photography</a></figcaption>\n</figure>\n\nThat is a neat definition, but what does it mean?\n\n**\"If we take a picture on instagram and apply a filter on it, is that computational photography?\"**\n\n**\"What if we digitally enhance our photographs after we take them?\"**\n\n**\"What about instagram filters?\"**\n\n\nIn its simplest form *computational photography* means anything that leverages the power of computer vision and image processing to artificially enhance photographs. This could be anything from a snapchat filter to an extremely sophisticated piece of code stitching together the first ever image of a black hole.\n\nBut before we fully understand what computational photography means let us go through a brief lesson on photography.\n\n### A primer on Photography\n\nIn simple terms we have a device which creates images by recording light reflected from real world objects on a sensor.\n\nThis means a camera essentially records light. Every little detail in a camera is to optimize that goal perfectly.\n\nSo if we *zoom* out a little and see the big picture, there are three main components to photography.\n\n1. How much light is entering the device? (The aperture)\n2. How long we are allowing the light to enter? (The shutter speed)\n3. How sensitive is the sensor to the light? (ISO)\n\nIf you are already familiar with these terms, and have some experience in creating images with various combinations of these parameters feel free to skip to the next section.\n\nAnd now, if you are still here, let us get started with the basic components of a camera.\n\n#### Aperture\n\nFirst we talk about Aperture. Now before we go all technical I want you to imagine something for me.\n\nFor a second, imagine that you are leaving a movie theatre. As you walk out, you are suddenly blinded by a flash of white light. You squeeze your eyes shut. It takes a couple of seconds for your eyes to readjust themselves to the brightness, and you slowly open them up again.\n\nSounds familiar?\n\nThis is exactly what **aperture** means.\n\nIt is the measure of how much the lens is opened. It is usually measured in f-stops and expressed in numbers such as 1.4,1.8,2,2.8,5.6,8,11,16.\n\nSomething to remember here is that the lower the number is the bigger the opening of the lens. The higher the f-stop is the smaller the opening of the lens.\n\n> But what effect does this have on the image?\n\nWell if you have a bigger opening you have more light or more information coming through. So a smaller aperture or larger f-stop would lead to darker pictures and vice versa.\n\n<figure>\n  <img src=\"/assets/images/6post/f-exposure.jpeg\" alt=\"exposure\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"https://samualross.wordpress.com/2014/11/24/a-beginners-guide-to-photography/\">A Beginners Guide to Photography</a></figcaption>\n</figure>\n\n> That's great, what else can we do using aperture?\n\n- The Aperture also controls Depth-Of-Field.\n\n> What is Depth-Of-Field?\n\nDepth-of-Field is simply the distance between the nearest and the farthest object in the camera's viewing field which are in acceptable focus.\n\nBy acceptable focus we mean that we can make out the details of the object.\n\n> But how is this connected to aperture?\n\nWell, the bigger the aperture the more light is allowed into the sensor creating a shallow depth of field for the background and vice versa.\n\n<figure>\n  <img src=\"/assets/images/6post/dof.png\" alt=\"depth of field\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"https://www.adorama.com/alc/what-is-f-stop-how-to-use-it-for-photography/\">What Is F-Stop & How to Use It for Photography</a></figcaption>\n</figure>\n\n#### Shutter Speed\n\nShutter speed is exactly what the name says. It is the speed with which the camera goes *khiichiiik*. This is usually measured in a fraction of a second for example, 1/10 th of a second. We can see numbers like 1/10,1/20,1/50,1/100,...,1/640.\n\nSo before I bring in the diagrams and the math, let me ask you a simple question- \n\n> What happens if we take a low shutter speed like 1/10?\n\nThe camera sensor stays open for a longer period of time right? This means we are allowing more light to enter. Our image will be brighter. \n\nSimilarly if we have a faster shutter speed, we will not give much time for the senor to be exposed to light. This means our image would be eventually darker.\n\n<figure>\n <img src=\"/assets/images/6post/shutter-speed.jpeg\" alt=\"shutter speed\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"https://www.nfi.edu/shutter-speed/\">Shutter Speed: Everything You Need To Know</a></figcaption>\n</figure>\n\n> This is great? Anything else?\n\nAbsolutely! We want to capture a high speed race car (in all its glorious details) - we would need a faster shutter speed. \n\nNow let us imagine that we want to capture a beautiful star trail from the Himalayas. We need to capture the movement of the stars, so we would need a low shutter speed.\n\n#### ISO\n\n> Wait, didn't we cover everything? What is ISO?\n\nISO stands for International Organization for Standardization and it stands for sensitivity to light. \n\nBefore we go into ISO for digital cameras , let us revisit the old days.\n\n<figure>\n <img src=\"/assets/images/6post/asa.jpeg\" alt=\"ASA\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"https://fineartamerica.com/featured/vintage-yashica-635-camera--asa-dial-jon-woodhams.html?product=greeting-card\">Vintage Yashica 635</a></figcaption>\n</figure>\n\nIn the film camera ISO or ASA as it was known in those days defined the sensitivity of the film's material to light. This is usually expressed in numbers such as 100,200,400,..1600. Now the lower the number is the less sensitive it is to light. \n\nWhich means in a low light environment the image would not be well exposed. Similarly if the ISO is higher, then in a low light environment it would still produce well exposed images.\n\n<figure>\n <img src=\"/assets/images/6post/iso.jpeg\" alt=\"ASA\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"http://www.getoffgreenauto.com/iso-exposure-exercise/\">ISO Exposure Exercise</a></figcaption>\n</figure>\n\nHowever for digital cameras ISO works differently. An image sensor is fundamentally different from a film one. Here the image is capture at a base ISO (100) always. When we select an ISO of 3200 a gain of 32X is applied to the already captured image.\n\nThe better the sensor the higher the tolerance of the gain.This means a good sesnor will be able to boost the image significantly without any noise, whereas a poor sensor will show noise in the image at lower values.\n\n> Note: The ISO in a digital camera is applying computational photography. The sensor and chip applies gains to the image **after** it is captured.\n\nAperture, shutter-speed and ISO are three pillars of photography. Together they control the amount of light entering the device. Here is an image commonly known as the *exposure triangle* that helps us understand the relationship between these three variables.\n\n<figure>\n <img src=\"/assets/images/6post/tri-factor.png\" alt=\"Triangle\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"https://www.polarprofilters.com/blogs/polarpro/the-three-elements-of-the-exposure-triangle\">The Three Elements of The Exposure Triangle</a></figcaption>\n</figure>\n\nA good photographer knows this by heart, a great photographer controls itðŸ˜Ž.\n\n### The Problems\n> But why do we need Computational Photography?\n\nEven the best of cameras have limitations. Some of them might be:\n\n- Creating a small aperture is costly and time consuming. However images for constricted aperture is more aesthetic. This presents a challenge: to achieve the same quality of images using larger apertures.\n\n- A small shutter speed for e.g 1/10 or 1/5 is realistically impossible for the human hand to keep still. Thus it is very difficult to take photographs for longer durations without a camera stand. \n\n- Not all camera sensors are built the same. A camera sensor that will allow a high ISO value without passing any noise in the output would be immensely costly.  Thus low light or night photography is completely trash in low end cameras.\n\nWith the dawn of the 21st Century science started challenging barriers and limitations. What was previously considered impossible is now one innovation away.\n\n> Computational Photography aims to solve these challenges leveraging the **minimal hardware requirements** possible.\n\nIn the next blogpost we will look at some methods adopted by smartphones and industry giants like Google and Apple to cater Computational Photography at scale.\n\n### Looking Back\n\nIn many ways photography began as an art form. The perfect instrument to capture moments. When it all began, photographs were taken and developed with care and attention in a dark room. The photographer worked hours to develop the photograph with only his memory as reference.\n\nWe moved from there to digital cameras that let us take photographs and visualise them instantly. The skill and dexterity of the photographer faded a little. He didn't need a masking tape and fine toothed brush and the right mix of chemicals to bring out details. \n\nAnd now we arrive at the present day, photographs are no longer taken but generated. Frames are stitched together and pixels are fused by massive algorithms to bring the best version of the photograph on screen. The phtographer no longer cares about elements of photography like aperture or shutter speed.\n\nMaybe this is the purpose of technology - to advance science and ease our lives in the process. But great photographs have been taken even in the harshest of limitations.\n\nAnd perhaps that is the meaning of art - beauty even in great adversity.\n\n### References\n\n- [Computational Photography - Wikipedia](https://en.wikipedia.org/wiki/Computational_photography)\n- [What is Computational Photography](https://www.dpreview.com/articles/9828658229/computational-photography-part-i-what-is-computational-photography)\n- [Definition of ISO](https://www.phototraces.com/definition-of-iso-in-photography/)\n- [History of ISO](https://expertphotography.com/understand-iso-4-simple-steps/)\n- [Mathemetical Expression of Noise](https://www.imatest.com/docs/noise/) ","srcMarkdownNoYaml":"\n\n> Computational photography refers to digital image capture and processing techniques that use digital computation instead of optical processes. - [Wikipedia](https://en.wikipedia.org/wiki/Computational_photography)\n\n<figure>\n  <img src=\"/assets/images/6post/apple.jpeg\" alt=\"image fusion\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"https://www.eoshd.com/comments/topic/38399-lets-discuss-computational-photography/\">Apple Computational Photography</a></figcaption>\n</figure>\n\nThat is a neat definition, but what does it mean?\n\n**\"If we take a picture on instagram and apply a filter on it, is that computational photography?\"**\n\n**\"What if we digitally enhance our photographs after we take them?\"**\n\n**\"What about instagram filters?\"**\n\n### TL;DR\n\nIn its simplest form *computational photography* means anything that leverages the power of computer vision and image processing to artificially enhance photographs. This could be anything from a snapchat filter to an extremely sophisticated piece of code stitching together the first ever image of a black hole.\n\nBut before we fully understand what computational photography means let us go through a brief lesson on photography.\n\n### A primer on Photography\n\nIn simple terms we have a device which creates images by recording light reflected from real world objects on a sensor.\n\nThis means a camera essentially records light. Every little detail in a camera is to optimize that goal perfectly.\n\nSo if we *zoom* out a little and see the big picture, there are three main components to photography.\n\n1. How much light is entering the device? (The aperture)\n2. How long we are allowing the light to enter? (The shutter speed)\n3. How sensitive is the sensor to the light? (ISO)\n\nIf you are already familiar with these terms, and have some experience in creating images with various combinations of these parameters feel free to skip to the next section.\n\nAnd now, if you are still here, let us get started with the basic components of a camera.\n\n#### Aperture\n\nFirst we talk about Aperture. Now before we go all technical I want you to imagine something for me.\n\nFor a second, imagine that you are leaving a movie theatre. As you walk out, you are suddenly blinded by a flash of white light. You squeeze your eyes shut. It takes a couple of seconds for your eyes to readjust themselves to the brightness, and you slowly open them up again.\n\nSounds familiar?\n\nThis is exactly what **aperture** means.\n\nIt is the measure of how much the lens is opened. It is usually measured in f-stops and expressed in numbers such as 1.4,1.8,2,2.8,5.6,8,11,16.\n\nSomething to remember here is that the lower the number is the bigger the opening of the lens. The higher the f-stop is the smaller the opening of the lens.\n\n> But what effect does this have on the image?\n\nWell if you have a bigger opening you have more light or more information coming through. So a smaller aperture or larger f-stop would lead to darker pictures and vice versa.\n\n<figure>\n  <img src=\"/assets/images/6post/f-exposure.jpeg\" alt=\"exposure\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"https://samualross.wordpress.com/2014/11/24/a-beginners-guide-to-photography/\">A Beginners Guide to Photography</a></figcaption>\n</figure>\n\n> That's great, what else can we do using aperture?\n\n- The Aperture also controls Depth-Of-Field.\n\n> What is Depth-Of-Field?\n\nDepth-of-Field is simply the distance between the nearest and the farthest object in the camera's viewing field which are in acceptable focus.\n\nBy acceptable focus we mean that we can make out the details of the object.\n\n> But how is this connected to aperture?\n\nWell, the bigger the aperture the more light is allowed into the sensor creating a shallow depth of field for the background and vice versa.\n\n<figure>\n  <img src=\"/assets/images/6post/dof.png\" alt=\"depth of field\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"https://www.adorama.com/alc/what-is-f-stop-how-to-use-it-for-photography/\">What Is F-Stop & How to Use It for Photography</a></figcaption>\n</figure>\n\n#### Shutter Speed\n\nShutter speed is exactly what the name says. It is the speed with which the camera goes *khiichiiik*. This is usually measured in a fraction of a second for example, 1/10 th of a second. We can see numbers like 1/10,1/20,1/50,1/100,...,1/640.\n\nSo before I bring in the diagrams and the math, let me ask you a simple question- \n\n> What happens if we take a low shutter speed like 1/10?\n\nThe camera sensor stays open for a longer period of time right? This means we are allowing more light to enter. Our image will be brighter. \n\nSimilarly if we have a faster shutter speed, we will not give much time for the senor to be exposed to light. This means our image would be eventually darker.\n\n<figure>\n <img src=\"/assets/images/6post/shutter-speed.jpeg\" alt=\"shutter speed\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"https://www.nfi.edu/shutter-speed/\">Shutter Speed: Everything You Need To Know</a></figcaption>\n</figure>\n\n> This is great? Anything else?\n\nAbsolutely! We want to capture a high speed race car (in all its glorious details) - we would need a faster shutter speed. \n\nNow let us imagine that we want to capture a beautiful star trail from the Himalayas. We need to capture the movement of the stars, so we would need a low shutter speed.\n\n#### ISO\n\n> Wait, didn't we cover everything? What is ISO?\n\nISO stands for International Organization for Standardization and it stands for sensitivity to light. \n\nBefore we go into ISO for digital cameras , let us revisit the old days.\n\n<figure>\n <img src=\"/assets/images/6post/asa.jpeg\" alt=\"ASA\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"https://fineartamerica.com/featured/vintage-yashica-635-camera--asa-dial-jon-woodhams.html?product=greeting-card\">Vintage Yashica 635</a></figcaption>\n</figure>\n\nIn the film camera ISO or ASA as it was known in those days defined the sensitivity of the film's material to light. This is usually expressed in numbers such as 100,200,400,..1600. Now the lower the number is the less sensitive it is to light. \n\nWhich means in a low light environment the image would not be well exposed. Similarly if the ISO is higher, then in a low light environment it would still produce well exposed images.\n\n<figure>\n <img src=\"/assets/images/6post/iso.jpeg\" alt=\"ASA\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"http://www.getoffgreenauto.com/iso-exposure-exercise/\">ISO Exposure Exercise</a></figcaption>\n</figure>\n\nHowever for digital cameras ISO works differently. An image sensor is fundamentally different from a film one. Here the image is capture at a base ISO (100) always. When we select an ISO of 3200 a gain of 32X is applied to the already captured image.\n\nThe better the sensor the higher the tolerance of the gain.This means a good sesnor will be able to boost the image significantly without any noise, whereas a poor sensor will show noise in the image at lower values.\n\n> Note: The ISO in a digital camera is applying computational photography. The sensor and chip applies gains to the image **after** it is captured.\n\nAperture, shutter-speed and ISO are three pillars of photography. Together they control the amount of light entering the device. Here is an image commonly known as the *exposure triangle* that helps us understand the relationship between these three variables.\n\n<figure>\n <img src=\"/assets/images/6post/tri-factor.png\" alt=\"Triangle\"/>\n  <figcaption style='text-align: center'>Source: <a href=\"https://www.polarprofilters.com/blogs/polarpro/the-three-elements-of-the-exposure-triangle\">The Three Elements of The Exposure Triangle</a></figcaption>\n</figure>\n\nA good photographer knows this by heart, a great photographer controls itðŸ˜Ž.\n\n### The Problems\n> But why do we need Computational Photography?\n\nEven the best of cameras have limitations. Some of them might be:\n\n- Creating a small aperture is costly and time consuming. However images for constricted aperture is more aesthetic. This presents a challenge: to achieve the same quality of images using larger apertures.\n\n- A small shutter speed for e.g 1/10 or 1/5 is realistically impossible for the human hand to keep still. Thus it is very difficult to take photographs for longer durations without a camera stand. \n\n- Not all camera sensors are built the same. A camera sensor that will allow a high ISO value without passing any noise in the output would be immensely costly.  Thus low light or night photography is completely trash in low end cameras.\n\nWith the dawn of the 21st Century science started challenging barriers and limitations. What was previously considered impossible is now one innovation away.\n\n> Computational Photography aims to solve these challenges leveraging the **minimal hardware requirements** possible.\n\nIn the next blogpost we will look at some methods adopted by smartphones and industry giants like Google and Apple to cater Computational Photography at scale.\n\n### Looking Back\n\nIn many ways photography began as an art form. The perfect instrument to capture moments. When it all began, photographs were taken and developed with care and attention in a dark room. The photographer worked hours to develop the photograph with only his memory as reference.\n\nWe moved from there to digital cameras that let us take photographs and visualise them instantly. The skill and dexterity of the photographer faded a little. He didn't need a masking tape and fine toothed brush and the right mix of chemicals to bring out details. \n\nAnd now we arrive at the present day, photographs are no longer taken but generated. Frames are stitched together and pixels are fused by massive algorithms to bring the best version of the photograph on screen. The phtographer no longer cares about elements of photography like aperture or shutter speed.\n\nMaybe this is the purpose of technology - to advance science and ease our lives in the process. But great photographs have been taken even in the harshest of limitations.\n\nAnd perhaps that is the meaning of art - beauty even in great adversity.\n\n### References\n\n- [Computational Photography - Wikipedia](https://en.wikipedia.org/wiki/Computational_photography)\n- [What is Computational Photography](https://www.dpreview.com/articles/9828658229/computational-photography-part-i-what-is-computational-photography)\n- [Definition of ISO](https://www.phototraces.com/definition-of-iso-in-photography/)\n- [History of ISO](https://expertphotography.com/understand-iso-4-simple-steps/)\n- [Mathemetical Expression of Noise](https://www.imatest.com/docs/noise/) "},"formats":{"html":{"identifier":{"display-name":"HTML","target-format":"html","base-format":"html"},"execute":{"fig-width":7,"fig-height":5,"fig-format":"retina","fig-dpi":96,"df-print":"default","error":false,"eval":true,"cache":null,"freeze":false,"echo":true,"output":true,"warning":true,"include":true,"keep-md":false,"keep-ipynb":false,"ipynb":null,"enabled":null,"daemon":null,"daemon-restart":false,"debug":false,"ipynb-filters":[],"ipynb-shell-interactivity":null,"plotly-connected":true,"engine":"markdown"},"render":{"keep-tex":false,"keep-typ":false,"keep-source":false,"keep-hidden":false,"prefer-html":false,"output-divs":true,"output-ext":"html","fig-align":"default","fig-pos":null,"fig-env":null,"code-fold":"none","code-overflow":"scroll","code-link":false,"code-line-numbers":false,"code-tools":false,"tbl-colwidths":"auto","merge-includes":true,"inline-includes":false,"preserve-yaml":false,"latex-auto-mk":true,"latex-auto-install":true,"latex-clean":true,"latex-min-runs":1,"latex-max-runs":10,"latex-makeindex":"makeindex","latex-makeindex-opts":[],"latex-tlmgr-opts":[],"latex-input-paths":[],"latex-output-dir":null,"link-external-icon":false,"link-external-newwindow":false,"self-contained-math":false,"format-resources":[],"notebook-links":true},"pandoc":{"standalone":true,"wrap":"none","default-image-extension":"png","to":"html","css":["../styles.css"],"toc":false,"output-file":"2022-01-18-what-is-computational-photography.html"},"language":{"toc-title-document":"Table of contents","toc-title-website":"On this page","related-formats-title":"Other Formats","related-notebooks-title":"Notebooks","source-notebooks-prefix":"Source","other-links-title":"Other Links","code-links-title":"Code Links","launch-dev-container-title":"Launch Dev Container","launch-binder-title":"Launch Binder","article-notebook-label":"Article Notebook","notebook-preview-download":"Download Notebook","notebook-preview-download-src":"Download Source","notebook-preview-back":"Back to Article","manuscript-meca-bundle":"MECA Bundle","section-title-abstract":"Abstract","section-title-appendices":"Appendices","section-title-footnotes":"Footnotes","section-title-references":"References","section-title-reuse":"Reuse","section-title-copyright":"Copyright","section-title-citation":"Citation","appendix-attribution-cite-as":"For attribution, please cite this work as:","appendix-attribution-bibtex":"BibTeX citation:","appendix-view-license":"View License","title-block-author-single":"Author","title-block-author-plural":"Authors","title-block-affiliation-single":"Affiliation","title-block-affiliation-plural":"Affiliations","title-block-published":"Published","title-block-modified":"Modified","title-block-keywords":"Keywords","callout-tip-title":"Tip","callout-note-title":"Note","callout-warning-title":"Warning","callout-important-title":"Important","callout-caution-title":"Caution","code-summary":"Code","code-tools-menu-caption":"Code","code-tools-show-all-code":"Show All Code","code-tools-hide-all-code":"Hide All Code","code-tools-view-source":"View Source","code-tools-source-code":"Source Code","tools-share":"Share","tools-download":"Download","code-line":"Line","code-lines":"Lines","copy-button-tooltip":"Copy to Clipboard","copy-button-tooltip-success":"Copied!","repo-action-links-edit":"Edit this page","repo-action-links-source":"View source","repo-action-links-issue":"Report an issue","back-to-top":"Back to top","search-no-results-text":"No results","search-matching-documents-text":"matching documents","search-copy-link-title":"Copy link to search","search-hide-matches-text":"Hide additional matches","search-more-match-text":"more match in this document","search-more-matches-text":"more matches in this document","search-clear-button-title":"Clear","search-text-placeholder":"","search-detached-cancel-button-title":"Cancel","search-submit-button-title":"Submit","search-label":"Search","toggle-section":"Toggle section","toggle-sidebar":"Toggle sidebar navigation","toggle-dark-mode":"Toggle dark mode","toggle-reader-mode":"Toggle reader mode","toggle-navigation":"Toggle navigation","crossref-fig-title":"Figure","crossref-tbl-title":"Table","crossref-lst-title":"Listing","crossref-thm-title":"Theorem","crossref-lem-title":"Lemma","crossref-cor-title":"Corollary","crossref-prp-title":"Proposition","crossref-cnj-title":"Conjecture","crossref-def-title":"Definition","crossref-exm-title":"Example","crossref-exr-title":"Exercise","crossref-ch-prefix":"Chapter","crossref-apx-prefix":"Appendix","crossref-sec-prefix":"Section","crossref-eq-prefix":"Equation","crossref-lof-title":"List of Figures","crossref-lot-title":"List of Tables","crossref-lol-title":"List of Listings","environment-proof-title":"Proof","environment-remark-title":"Remark","environment-solution-title":"Solution","listing-page-order-by":"Order By","listing-page-order-by-default":"Default","listing-page-order-by-date-asc":"Oldest","listing-page-order-by-date-desc":"Newest","listing-page-order-by-number-desc":"High to Low","listing-page-order-by-number-asc":"Low to High","listing-page-field-date":"Date","listing-page-field-title":"Title","listing-page-field-description":"Description","listing-page-field-author":"Author","listing-page-field-filename":"File Name","listing-page-field-filemodified":"Modified","listing-page-field-subtitle":"Subtitle","listing-page-field-readingtime":"Reading Time","listing-page-field-wordcount":"Word Count","listing-page-field-categories":"Categories","listing-page-minutes-compact":"{0} min","listing-page-category-all":"All","listing-page-no-matches":"No matching items","listing-page-words":"{0} words","listing-page-filter":"Filter","draft":"Draft"},"metadata":{"lang":"en","fig-responsive":true,"quarto-version":"1.7.32","title":"What is Computational Photography","date":"2022-01-18","author":"Ritwik Raha","tags":["math","image-processing"],"image":"/assets/images/computational-1.png"},"extensions":{"book":{"multiFile":true}}}},"projectFormats":["html"]}